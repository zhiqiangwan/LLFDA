{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import glob\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd512_Siamese import ssd_512\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation, SSDDataAugmentation_Siamese\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "\n",
    "img_height = 512  # Height of the model input images\n",
    "img_width = 512  # Width of the model input images\n",
    "img_channels = 3  # Number of color channels of the model input images\n",
    "mean_color = [123, 117, 104]  # Per-channel mean of images. Do not change if use any of the pre-trained weights.\n",
    "# The color channel order in the original SSD is BGR,\n",
    "# so we'll have the model reverse the color channel order of the input images.\n",
    "swap_channels = [2, 1, 0]\n",
    "# The anchor box scaling factors used in the original SSD512 for the Pascal VOC datasets\n",
    "# scales_pascal =\n",
    "# The anchor box scaling factors used in the original SSD512 for the MS COCO datasets\n",
    "scales_coco = [0.07, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1.05]\n",
    "scales = scales_coco\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]]  # The anchor box aspect ratios used in the original SSD512; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [8, 16, 32, 64, 128, 256, 512]  # Space between two adjacent anchor box center points for each predictor layer.\n",
    "# The offsets of the first anchor box center points from the top and left borders of the image\n",
    "# as a fraction of the step size for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "clip_boxes = False  # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "# The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "variances = [0.1, 0.1, 0.2, 0.2]\n",
    "normalize_coords = True\n",
    "Model_Build = 'New_Model'  # 'Load_Model'\n",
    "Optimizer_Type = 'SGD'  # 'Adam'  #\n",
    "# Different batch_size will have different prediction loss.\n",
    "batch_size = 8  # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "# alpha_distance = 0.0001  # Coefficient for the distance between the source and target feature maps.\n",
    "loss_weights = [0.0, 0.000005, 0.0] + [1.0]\n",
    "Source_Only = False\n",
    "\n",
    "# 'City_to_foggy0_01_resize_600_1200' # 'City_to_foggy0_02_resize_600_1200'  # 'SIM10K_to_VOC07'\n",
    "# 'SIM10K'  # 'Cityscapes_foggy_beta_0_01'  #  'City_to_foggy0_02_resize_400_800'\n",
    "DatasetName = 'City_to_foggy0_01_resize_400_800' # 'SIM10K_to_City_resize_400_800'\n",
    "processed_dataset_path = './processed_dataset_h5/' + DatasetName\n",
    "if not os.path.exists(processed_dataset_path):\n",
    "    os.makedirs(processed_dataset_path)\n",
    "\n",
    "if len(glob.glob(os.path.join(processed_dataset_path, '*.h5'))):\n",
    "    Dataset_Build = 'Load_Dataset'\n",
    "else:\n",
    "    Dataset_Build = 'New_Dataset'\n",
    "\n",
    "if DatasetName == 'SIM10K_to_City_resize_400_800':\n",
    "    resize_image_to = (400, 800)\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/SIM10K/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/val_data_for_SIM10K_to_cityscapes/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/SIM10K/Annotations'\n",
    "    test_annotation_dir = '../../datasets/val_data_for_SIM10K_to_cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/SIM10K/ImageSets/Main/trainval10k.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    test_target_image_set_filename = '../../datasets/val_data_for_SIM10K_to_cityscapes/ImageSets/Main/test.txt'\n",
    "\n",
    "    classes = ['background', 'car']  # Our model will produce predictions for these classes.\n",
    "    train_classes = ['background', 'car', 'motorbike', 'person']  # The train_source dataset contains these classes.\n",
    "    train_include_classes = [train_classes.index(one_class) for one_class in classes[1:]]\n",
    "    # The test_target dataset contains these classes.\n",
    "    val_classes = ['background', 'car']\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'City_to_foggy0_02_resize_400_800':\n",
    "    resize_image_to = (400, 800)\n",
    "    # Introduction of PascalVOC: https://arleyzhang.github.io/articles/1dc20586/\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "    test_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_target.txt'\n",
    "    test_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/test.txt'\n",
    "    # Our model will produce predictions for these classes.\n",
    "    classes = ['background',\n",
    "               'person', 'rider', 'car', 'truck',\n",
    "               'bus', 'train', 'motorcycle', 'bicycle']\n",
    "    train_classes = classes\n",
    "    train_include_classes = 'all'\n",
    "    val_classes = classes\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'City_to_foggy0_01_resize_400_800':\n",
    "    resize_image_to = (400, 800)\n",
    "    # Introduction of PascalVOC: https://arleyzhang.github.io/articles/1dc20586/\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/CITYSCAPES_beta_0_01/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/CITYSCAPES_beta_0_01/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "    test_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_target.txt'\n",
    "    test_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/test.txt'\n",
    "    # Our model will produce predictions for these classes.\n",
    "    classes = ['background',\n",
    "               'person', 'rider', 'car', 'truck',\n",
    "               'bus', 'train', 'motorcycle', 'bicycle']\n",
    "    train_classes = classes\n",
    "    train_include_classes = 'all'\n",
    "    val_classes = classes\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'City_to_foggy0_01_resize_600_1200':\n",
    "    resize_image_to = (600, 1200)\n",
    "    # Introduction of PascalVOC: https://arleyzhang.github.io/articles/1dc20586/\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/CITYSCAPES_beta_0_01/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/CITYSCAPES_beta_0_01/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "    test_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_target.txt'\n",
    "    test_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/test.txt'\n",
    "    # Our model will produce predictions for these classes.\n",
    "    classes = ['background',\n",
    "               'person', 'rider', 'car', 'truck',\n",
    "               'bus', 'train', 'motorcycle', 'bicycle']\n",
    "    train_classes = classes\n",
    "    train_include_classes = 'all'\n",
    "    val_classes = classes\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'City_to_foggy0_02_resize_600_1200':\n",
    "    resize_image_to = (600, 1200)\n",
    "    # Introduction of PascalVOC: https://arleyzhang.github.io/articles/1dc20586/\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "    test_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_target.txt'\n",
    "    test_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/test.txt'\n",
    "    # Our model will produce predictions for these classes.\n",
    "    classes = ['background',\n",
    "               'person', 'rider', 'car', 'truck',\n",
    "               'bus', 'train', 'motorcycle', 'bicycle']\n",
    "    train_classes = classes\n",
    "    train_include_classes = 'all'\n",
    "    val_classes = classes\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'Cityscapes_foggy_beta_0_01':\n",
    "    resize_image_to = (300, 600)\n",
    "    # Introduction of PascalVOC: https://arleyzhang.github.io/articles/1dc20586/\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/CITYSCAPES_beta_0_01/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/CITYSCAPES_beta_0_01/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "    test_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_target.txt'\n",
    "    test_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/test.txt'\n",
    "    # Our model will produce predictions for these classes.\n",
    "    classes = ['background',\n",
    "               'person', 'rider', 'car', 'truck',\n",
    "               'bus', 'train', 'motorcycle', 'bicycle']\n",
    "    train_classes = classes\n",
    "    train_include_classes = 'all'\n",
    "    val_classes = classes\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'SIM10K':\n",
    "    resize_image_to = (300, 600)\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/SIM10K/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/val_data_for_SIM10K_to_cityscapes/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/SIM10K/Annotations'\n",
    "    test_annotation_dir = '../../datasets/val_data_for_SIM10K_to_cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/SIM10K/ImageSets/Main/trainval10k.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    test_target_image_set_filename = '../../datasets/val_data_for_SIM10K_to_cityscapes/ImageSets/Main/test.txt'\n",
    "\n",
    "    classes = ['background', 'car']  # Our model will produce predictions for these classes.\n",
    "    train_classes = ['background', 'car', 'motorbike', 'person']  # The train_source dataset contains these classes.\n",
    "    train_include_classes = [train_classes.index(one_class) for one_class in classes[1:]]\n",
    "    # The test_target dataset contains these classes.\n",
    "    val_classes = ['background', 'car']\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'SIM10K_to_VOC07':\n",
    "    resize_image_to = (300, 600)\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/SIM10K/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/VOCdevkit/VOC2007/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/VOCdevkit/VOC2007/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/SIM10K/Annotations'\n",
    "    test_annotation_dir = '../../datasets/VOCdevkit/VOC2007/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/SIM10K/ImageSets/Main/trainval10k.txt'\n",
    "    # The trainset of VOC which has 'car' object is used as train_target.\n",
    "    train_target_image_set_filename = '../../datasets/VOCdevkit/VOC2007_CAR/ImageSets/Main/train_target.txt'\n",
    "    # The valset of VOC which has 'car' object is used as test.\n",
    "    test_target_image_set_filename = '../../datasets/VOCdevkit/VOC2007_CAR/ImageSets/Main/test.txt'\n",
    "\n",
    "    classes = ['background', 'car']  # Our model will produce predictions for these classes.\n",
    "    train_classes = ['background', 'car', 'motorbike', 'person']  # The train_source dataset contains these classes.\n",
    "    train_include_classes = [train_classes.index(one_class) for one_class in classes[1:]]\n",
    "    # The test_target dataset contains these classes.\n",
    "    val_classes = ['background', 'car',\n",
    "                   'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                   'bottle', 'bus', 'cat',\n",
    "                   'chair', 'cow', 'diningtable', 'dog',\n",
    "                   'horse', 'motorbike', 'person', 'pottedplant',\n",
    "                   'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "    val_include_classes = [val_classes.index(one_class) for one_class in classes[1:]]\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "else:\n",
    "    raise ValueError('Undefined dataset name.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Model_Build == 'New_Model':\n",
    "    # 1: Build the Keras model.\n",
    "\n",
    "    K.clear_session()  # Clear previous models from memory.\n",
    "\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "    model = ssd_512(image_size=(img_height, img_width, img_channels),\n",
    "                    n_classes=n_classes,\n",
    "                    mode='training',\n",
    "                    l2_regularization=0.0005,\n",
    "                    scales=scales,\n",
    "                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                    steps=steps,\n",
    "                    offsets=offsets,\n",
    "                    clip_boxes=clip_boxes,\n",
    "                    variances=variances,\n",
    "                    normalize_coords=normalize_coords,\n",
    "                    subtract_mean=mean_color,\n",
    "                    swap_channels=swap_channels)\n",
    "\n",
    "    # 2: Load some weights into the model.\n",
    "\n",
    "    # TODO: Set the path to the weights you want to load.\n",
    "    weights_path = '../trained_weights/VGG_ILSVRC_16_layers_fc_reduced.h5'\n",
    "\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    # 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "    #    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "    #    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "    if Optimizer_Type == 'SGD':\n",
    "        Optimizer = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n",
    "    elif Optimizer_Type == 'Adam':\n",
    "        Optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    else:\n",
    "        raise ValueError('Undefined Optimizer_Type.')\n",
    "\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "    model.compile(optimizer=Optimizer, loss={'pool1_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "                                             'pool2_GAP_substract': ssd_loss.compute_distance_loss,\n",
    "                                             'pool3_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "                                             'predictions': ssd_loss.compute_loss},\n",
    "                  loss_weights={'pool1_GAP_substract': loss_weights[0],\n",
    "                                'pool2_GAP_substract': loss_weights[1],\n",
    "                                'pool3_GAP_substract': loss_weights[2],\n",
    "                                'predictions': loss_weights[3]})    \n",
    "    \n",
    "#     if Source_Only:\n",
    "#         model.compile(optimizer=Optimizer, loss={'pool1_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "#                                                  'pool2_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "#                                                  'pool3_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "#                                                  'predictions': ssd_loss.compute_loss},\n",
    "#                       loss_weights={'pool1_GAP_substract': loss_weights[0],\n",
    "#                                     'pool2_GAP_substract': loss_weights[1],\n",
    "#                                     'pool3_GAP_substract': loss_weights[2],\n",
    "#                                     'predictions': loss_weights[3]})\n",
    "#     else:\n",
    "#         model.compile(optimizer=Optimizer, loss={'pool1_GAP_substract': ssd_loss.compute_distance_loss,\n",
    "#                                                  'pool2_GAP_substract': ssd_loss.compute_distance_loss,\n",
    "#                                                  'pool3_GAP_substract': ssd_loss.compute_distance_loss,\n",
    "#                                                  'predictions': ssd_loss.compute_loss},\n",
    "#                       loss_weights={'pool1_GAP_substract': loss_weights[0],\n",
    "#                                     'pool2_GAP_substract': loss_weights[1],\n",
    "#                                     'pool3_GAP_substract': loss_weights[2],\n",
    "#                                     'predictions': loss_weights[3]})\n",
    "\n",
    "elif Model_Build == 'Load_Model':\n",
    "    # TODO: Set the path to the `.h5` file of the model to be loaded.\n",
    "    model_path = '../trained_weights/VGG_ssd300_Cityscapes/epoch-23_loss-5.2110_val_loss-6.7452.h5'\n",
    "\n",
    "    # We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "    K.clear_session()  # Clear previous models from memory.\n",
    "\n",
    "    # import tensorflow as tf\n",
    "    # from keras.backend.tensorflow_backend import set_session\n",
    "    #\n",
    "    # config = tf.ConfigProto()\n",
    "    # config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    # config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "    # # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "    # sess = tf.Session(config=config)\n",
    "    # set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "    model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                                   'L2Normalization': L2Normalization,\n",
    "                                                   'compute_loss': ssd_loss.compute_loss,\n",
    "                                                   'compute_distance_loss': ssd_loss.compute_distance_loss})\n",
    "else:\n",
    "    raise ValueError('Undefined Model_Build. Model_Build should be New_Model  or Load_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source labels: 100%|██████████| 2966/2966 [00:00<00:00, 4350.89it/s]\n",
      "Loading source image IDs: 100%|██████████| 2966/2966 [00:00<00:00, 10379.47it/s]\n",
      "Loading target image IDs: 100%|██████████| 2966/2966 [00:00<00:00, 10838.02it/s]\n",
      "Loading evaluation-neutrality annotations: 100%|██████████| 2966/2966 [00:00<00:00, 7437.63it/s]\n",
      "Loading source labels: 100%|██████████| 493/493 [00:00<00:00, 4382.01it/s]\n",
      "Loading source image IDs: 100%|██████████| 493/493 [00:00<00:00, 8089.41it/s]\n",
      "Loading target image IDs: 0it [00:00, ?it/s]\n",
      "Loading evaluation-neutrality annotations: 100%|██████████| 493/493 [00:00<00:00, 6121.98it/s]\n"
     ]
    }
   ],
   "source": [
    "if Dataset_Build == 'New_Dataset':\n",
    "    # 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "    # Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "    train_dataset = DataGenerator(dataset='train', load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "    val_dataset = DataGenerator(dataset='val', load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "\n",
    "    # 2: Parse the image and label lists for the training and validation datasets. This can take a while.\n",
    "    # images_dirs, image_set_filenames, and annotations_dirs should have the same length\n",
    "    train_dataset.parse_xml(images_dirs=[train_source_images_dir],\n",
    "                            target_images_dirs=[train_target_images_dir],\n",
    "                            image_set_filenames=[train_source_image_set_filename],\n",
    "                            target_image_set_filenames=[train_target_image_set_filename],\n",
    "                            annotations_dirs=[train_annotation_dir],\n",
    "                            classes=train_classes,\n",
    "                            include_classes=train_include_classes,\n",
    "                            exclude_truncated=False,\n",
    "                            exclude_difficult=False,\n",
    "                            ret=False)\n",
    "\n",
    "    val_dataset.parse_xml(images_dirs=[test_target_images_dir],\n",
    "                          image_set_filenames=[test_target_image_set_filename],\n",
    "                          annotations_dirs=[test_annotation_dir],\n",
    "                          classes=val_classes,\n",
    "                          include_classes=val_include_classes,\n",
    "                          exclude_truncated=False,\n",
    "                          exclude_difficult=True,\n",
    "                          ret=False)\n",
    "\n",
    "    # Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
    "    # speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
    "    # option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
    "    # want to create HDF5 datasets, comment out the subsequent two function calls.\n",
    "\n",
    "    # After create these h5 files, if you have resized the input image, you need to reload these files. Otherwise,\n",
    "    # the images and the labels will not change.\n",
    "\n",
    "    train_dataset.create_hdf5_dataset(file_path=os.path.join(processed_dataset_path, 'dataset_train.h5'),\n",
    "                                      resize=resize_image_to,\n",
    "                                      variable_image_size=True,\n",
    "                                      verbose=True)\n",
    "\n",
    "    val_dataset.create_hdf5_dataset(file_path=os.path.join(processed_dataset_path, 'dataset_test.h5'),\n",
    "                                    resize=False,\n",
    "                                    variable_image_size=True,\n",
    "                                    verbose=True)\n",
    "\n",
    "    train_dataset = DataGenerator(dataset='train',\n",
    "                                  load_images_into_memory=False,\n",
    "                                  hdf5_dataset_path=os.path.join(processed_dataset_path, 'dataset_train.h5'),\n",
    "                                  filenames=train_source_image_set_filename,\n",
    "                                  target_filenames=train_target_image_set_filename,\n",
    "                                  filenames_type='text',\n",
    "                                  images_dir=train_source_images_dir,\n",
    "                                  target_images_dir=train_target_images_dir)\n",
    "\n",
    "    val_dataset = DataGenerator(dataset='val',\n",
    "                                load_images_into_memory=False,\n",
    "                                hdf5_dataset_path=os.path.join(processed_dataset_path, 'dataset_test.h5'),\n",
    "                                filenames=test_target_image_set_filename,\n",
    "                                filenames_type='text',\n",
    "                                images_dir=test_target_images_dir)\n",
    "\n",
    "elif Dataset_Build == 'Load_Dataset':\n",
    "    # 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "    # Load dataset from the created h5 file.\n",
    "    train_dataset = DataGenerator(dataset='train',\n",
    "                                  load_images_into_memory=False,\n",
    "                                  hdf5_dataset_path=os.path.join(processed_dataset_path, 'dataset_train.h5'),\n",
    "                                  filenames=train_source_image_set_filename,\n",
    "                                  target_filenames=train_target_image_set_filename,\n",
    "                                  filenames_type='text',\n",
    "                                  images_dir=train_source_images_dir,\n",
    "                                  target_images_dir=train_target_images_dir)\n",
    "\n",
    "    val_dataset = DataGenerator(dataset='val',\n",
    "                                load_images_into_memory=False,\n",
    "                                hdf5_dataset_path=os.path.join(processed_dataset_path, 'dataset_test.h5'),\n",
    "                                filenames=test_target_image_set_filename,\n",
    "                                filenames_type='text',\n",
    "                                images_dir=test_target_images_dir)\n",
    "\n",
    "else:\n",
    "    raise ValueError('Undefined Dataset_Build. Dataset_Build should be New_Dataset or Load_Dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t  2966\n",
      "Number of images in the validation dataset:\t   493\n"
     ]
    }
   ],
   "source": [
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation_Siamese(img_height=img_height,\n",
    "                                                    img_width=img_width)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('conv4_3_norm_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('fc7_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv6_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv7_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv8_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv9_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv10_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "# The input image and label are first processed by transformations. Then, the label will be further encoded by\n",
    "# ssd_input_encoder. The encoded labels are classId and offset to each anchor box.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    if epoch < 2:\n",
    "        return 0.0005\n",
    "    elif epoch < 50:\n",
    "        return 0.001\n",
    "    elif epoch < 70:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00001\n",
    "\n",
    "# def lr_schedule(epoch):\n",
    "#     if epoch < 50:\n",
    "#         return 0.001\n",
    "#     elif epoch < 60:\n",
    "#         return 0.0001\n",
    "#     else:\n",
    "#         return 0.00001\n",
    "\n",
    "# Define model callbacks.\n",
    "checkpoint_path = '../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005'\n",
    "# checkpoint_path = '../trained_weights/current/ssd_augm_beta_0_01_source_only'\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath=os.path.join(checkpoint_path, 'epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5'),\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=False,\n",
    "                                   save_weights_only=True,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "# model_checkpoint.best to the best validation loss from the previous training\n",
    "# model_checkpoint.best = 4.83704\n",
    "\n",
    "csv_logger = CSVLogger(filename=os.path.join(checkpoint_path, 'pool2_loss_weights_0_000005_training_log.csv'),\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule,\n",
    "                                                verbose=1)\n",
    "\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "TensorBoard_monitor = TensorBoard(log_dir=checkpoint_path)\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             learning_rate_scheduler,\n",
    "             terminate_on_nan,\n",
    "             TensorBoard_monitor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 757s 757ms/step - loss: 15.9832 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 16440.6098 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 12.2282 - val_loss: 10.4029 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.7413\n",
      "\n",
      "Epoch 00001: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-01_loss-15.9832_val_loss-10.4029.h5\n",
      "Epoch 2/120\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 749s 749ms/step - loss: 9.7973 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 3064.7008 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 6.1382 - val_loss: 10.1008 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.4751\n",
      "\n",
      "Epoch 00002: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-02_loss-9.7973_val_loss-10.1008.h5\n",
      "Epoch 3/120\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 749s 749ms/step - loss: 9.7796 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 2554.5425 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 6.1750 - val_loss: 10.7944 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.2369\n",
      "\n",
      "Epoch 00003: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-03_loss-9.7796_val_loss-10.7944.h5\n",
      "Epoch 4/120\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 752s 752ms/step - loss: 9.0585 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 2013.7835 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 5.5250 - val_loss: 9.4344 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 5.9448\n",
      "\n",
      "Epoch 00004: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-04_loss-9.0585_val_loss-9.4344.h5\n",
      "Epoch 5/120\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 749s 749ms/step - loss: 8.8274 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 1752.5377 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 5.3624 - val_loss: 9.3980 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 5.9750\n",
      "\n",
      "Epoch 00005: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-05_loss-8.8274_val_loss-9.3980.h5\n",
      "Epoch 6/120\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 813s 813ms/step - loss: 8.6460 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 1524.4153 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 5.2481 - val_loss: 8.9769 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 5.6192\n",
      "\n",
      "Epoch 00006: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-06_loss-8.6460_val_loss-8.9769.h5\n",
      "Epoch 7/120\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 750s 750ms/step - loss: 8.4948 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 1371.1293 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 5.1623 - val_loss: 8.8998 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 5.6061\n",
      "\n",
      "Epoch 00007: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-07_loss-8.4948_val_loss-8.8998.h5\n",
      "Epoch 8/120\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 750s 750ms/step - loss: 8.3399 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 1223.4523 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 5.0714 - val_loss: 8.8518 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 5.6206\n",
      "\n",
      "Epoch 00008: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-08_loss-8.3399_val_loss-8.8518.h5\n",
      "Epoch 9/120\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 750s 750ms/step - loss: 8.1764 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 1108.8731 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 4.9705 - val_loss: 8.6822 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 5.5126\n",
      "\n",
      "Epoch 00009: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-09_loss-8.1764_val_loss-8.6822.h5\n",
      "Epoch 10/120\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 756s 756ms/step - loss: 8.0742 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 1001.9597 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 4.9297 - val_loss: 8.7645 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 5.6551\n",
      "\n",
      "Epoch 00010: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-10_loss-8.0742_val_loss-8.7645.h5\n",
      "Epoch 11/120\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 750s 750ms/step - loss: 7.9613 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 888.9301 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 4.8770 - val_loss: 8.6230 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 5.5725\n",
      "\n",
      "Epoch 00011: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-11_loss-7.9613_val_loss-8.6230.h5\n",
      "Epoch 12/120\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 754s 754ms/step - loss: 7.8867 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 837.7439 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 4.8609 - val_loss: 8.3894 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 5.3966\n",
      "\n",
      "Epoch 00012: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-12_loss-7.8867_val_loss-8.3894.h5\n",
      "Epoch 13/120\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 751s 751ms/step - loss: 7.8010 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 778.0313 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 4.8326 - val_loss: 8.5635 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 5.6271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-13_loss-7.8010_val_loss-8.5635.h5\n",
      "Epoch 14/120\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 751s 751ms/step - loss: 7.7306 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 722.5932 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 4.8184 - val_loss: 8.6762 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 5.7951\n",
      "\n",
      "Epoch 00014: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-14_loss-7.7306_val_loss-8.6762.h5\n",
      "Epoch 15/120\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 750s 750ms/step - loss: 7.5755 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 721.2919 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 4.7178 - val_loss: 8.2337 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 5.4062\n",
      "\n",
      "Epoch 00015: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-15_loss-7.5755_val_loss-8.2337.h5\n",
      "Epoch 16/120\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 751s 751ms/step - loss: 7.1864 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 780.7751 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 4.3804 - val_loss: 7.9146 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 5.1372\n",
      "\n",
      "Epoch 00016: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-16_loss-7.1864_val_loss-7.9146.h5\n",
      "Epoch 17/120\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 750s 750ms/step - loss: 6.7970 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 842.8295 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 4.0396 - val_loss: 7.5313 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.8021\n",
      "\n",
      "Epoch 00017: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-17_loss-6.7970_val_loss-7.5313.h5\n",
      "Epoch 18/120\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 750s 750ms/step - loss: 6.5385 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 904.2517 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.8281 - val_loss: 7.3603 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.6776\n",
      "\n",
      "Epoch 00018: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-18_loss-6.5385_val_loss-7.3603.h5\n",
      "Epoch 19/120\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 751s 751ms/step - loss: 6.3603 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 891.5215 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.6959 - val_loss: 7.1625 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.5252\n",
      "\n",
      "Epoch 00019: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-19_loss-6.3603_val_loss-7.1625.h5\n",
      "Epoch 20/120\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 751s 751ms/step - loss: 6.2332 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 850.8737 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.6140 - val_loss: 6.9175 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.3248\n",
      "\n",
      "Epoch 00020: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-20_loss-6.2332_val_loss-6.9175.h5\n",
      "Epoch 21/120\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 751s 751ms/step - loss: 6.1058 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 881.7425 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.5305 - val_loss: 7.0303 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.4811\n",
      "\n",
      "Epoch 00021: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-21_loss-6.1058_val_loss-7.0303.h5\n",
      "Epoch 22/120\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 752s 752ms/step - loss: 5.9298 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 879.2970 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.3976 - val_loss: 7.0873 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.5809\n",
      "\n",
      "Epoch 00022: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-22_loss-5.9298_val_loss-7.0873.h5\n",
      "Epoch 23/120\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 750s 750ms/step - loss: 5.8945 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 850.4538 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.4047 - val_loss: 7.0535 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.5887\n",
      "\n",
      "Epoch 00023: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-23_loss-5.8945_val_loss-7.0535.h5\n",
      "Epoch 24/120\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 751s 751ms/step - loss: 5.7691 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 850.7474 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.3203 - val_loss: 6.8125 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.3883\n",
      "\n",
      "Epoch 00024: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-24_loss-5.7691_val_loss-6.8125.h5\n",
      "Epoch 25/120\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 752s 752ms/step - loss: 5.6961 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 832.4082 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.2877 - val_loss: 6.6846 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.3002\n",
      "\n",
      "Epoch 00025: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-25_loss-5.6961_val_loss-6.6846.h5\n",
      "Epoch 26/120\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 755s 755ms/step - loss: 5.6139 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 807.9121 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.2451 - val_loss: 6.5951 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.2498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-26_loss-5.6139_val_loss-6.5951.h5\n",
      "Epoch 27/120\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 753s 753ms/step - loss: 5.4987 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 828.3186 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.1684 - val_loss: 6.7546 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.4475\n",
      "\n",
      "Epoch 00027: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-27_loss-5.4987_val_loss-6.7546.h5\n",
      "Epoch 28/120\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 753s 753ms/step - loss: 5.4513 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 823.6871 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.1586 - val_loss: 6.6495 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.3795\n",
      "\n",
      "Epoch 00028: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-28_loss-5.4513_val_loss-6.6495.h5\n",
      "Epoch 29/120\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 753s 753ms/step - loss: 5.3940 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 850.6953 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.1379 - val_loss: 6.4117 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.1779\n",
      "\n",
      "Epoch 00029: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-29_loss-5.3940_val_loss-6.4117.h5\n",
      "Epoch 30/120\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 766s 766ms/step - loss: 5.3178 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 767.9804 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.0981 - val_loss: 6.3476 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.1494\n",
      "\n",
      "Epoch 00030: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-30_loss-5.3178_val_loss-6.3476.h5\n",
      "Epoch 31/120\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 780s 780ms/step - loss: 5.2900 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 802.6310 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.1053 - val_loss: 6.2702 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.1069\n",
      "\n",
      "Epoch 00031: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-31_loss-5.2900_val_loss-6.2702.h5\n",
      "Epoch 32/120\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 775s 775ms/step - loss: 5.1967 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 746.0796 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.0468 - val_loss: 6.2975 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.1684\n",
      "\n",
      "Epoch 00032: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-32_loss-5.1967_val_loss-6.2975.h5\n",
      "Epoch 33/120\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 752s 752ms/step - loss: 5.1526 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 775.0540 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 3.0362 - val_loss: 6.4442 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.3483\n",
      "\n",
      "Epoch 00033: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-33_loss-5.1526_val_loss-6.4442.h5\n",
      "Epoch 34/120\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 778s 778ms/step - loss: 5.0671 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 752.9128 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.9839 - val_loss: 6.2523 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.1892\n",
      "\n",
      "Epoch 00034: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-34_loss-5.0671_val_loss-6.2523.h5\n",
      "Epoch 35/120\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 766s 766ms/step - loss: 5.0170 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 732.1602 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.9663 - val_loss: 6.0489 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.0177\n",
      "\n",
      "Epoch 00035: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-35_loss-5.0170_val_loss-6.0489.h5\n",
      "Epoch 36/120\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 773s 773ms/step - loss: 4.9126 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 711.2681 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.8936 - val_loss: 6.1670 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.1672\n",
      "\n",
      "Epoch 00036: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-36_loss-4.9126_val_loss-6.1670.h5\n",
      "Epoch 37/120\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 771s 771ms/step - loss: 4.9682 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 751.0256 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.9800 - val_loss: 6.2118 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.2426\n",
      "\n",
      "Epoch 00037: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-37_loss-4.9682_val_loss-6.2118.h5\n",
      "Epoch 38/120\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 774s 774ms/step - loss: 4.9088 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 753.8820 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.9507 - val_loss: 5.9962 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.0566\n",
      "\n",
      "Epoch 00038: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-38_loss-4.9088_val_loss-5.9962.h5\n",
      "Epoch 39/120\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 781s 781ms/step - loss: 4.8383 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 720.8844 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.9098 - val_loss: 6.1325 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.2221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00039: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-39_loss-4.8383_val_loss-6.1325.h5\n",
      "Epoch 40/120\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 784s 784ms/step - loss: 4.7896 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 740.0723 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.8899 - val_loss: 6.0712 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.1896\n",
      "\n",
      "Epoch 00040: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-40_loss-4.7896_val_loss-6.0712.h5\n",
      "Epoch 41/120\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 775s 775ms/step - loss: 4.7564 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 706.4316 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.8853 - val_loss: 5.8751 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.0213\n",
      "\n",
      "Epoch 00041: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-41_loss-4.7564_val_loss-5.8751.h5\n",
      "Epoch 42/120\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 770s 770ms/step - loss: 4.7042 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 704.5894 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.8608 - val_loss: 6.0701 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.2439\n",
      "\n",
      "Epoch 00042: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-42_loss-4.7042_val_loss-6.0701.h5\n",
      "Epoch 43/120\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 777s 777ms/step - loss: 4.6704 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 661.5390 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.8543 - val_loss: 6.0096 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.2102\n",
      "\n",
      "Epoch 00043: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-43_loss-4.6704_val_loss-6.0096.h5\n",
      "Epoch 44/120\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 771s 771ms/step - loss: 4.6155 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 688.2072 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.8258 - val_loss: 6.2051 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.4320\n",
      "\n",
      "Epoch 00044: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-44_loss-4.6155_val_loss-6.2051.h5\n",
      "Epoch 45/120\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 770s 770ms/step - loss: 4.5816 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 657.8172 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.8182 - val_loss: 5.7748 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.0275\n",
      "\n",
      "Epoch 00045: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-45_loss-4.5816_val_loss-5.7748.h5\n",
      "Epoch 46/120\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 764s 764ms/step - loss: 4.5341 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 667.6813 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.7961 - val_loss: 5.7720 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.0499\n",
      "\n",
      "Epoch 00046: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-46_loss-4.5341_val_loss-5.7720.h5\n",
      "Epoch 47/120\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 777s 777ms/step - loss: 4.5242 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 660.5163 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.8110 - val_loss: 5.9070 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.2092\n",
      "\n",
      "Epoch 00047: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-47_loss-4.5242_val_loss-5.9070.h5\n",
      "Epoch 48/120\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 755s 755ms/step - loss: 4.4934 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 661.0409 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.8044 - val_loss: 5.7722 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.0984\n",
      "\n",
      "Epoch 00048: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-48_loss-4.4934_val_loss-5.7722.h5\n",
      "Epoch 49/120\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 754s 754ms/step - loss: 4.4198 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 697.1311 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.7544 - val_loss: 5.5337 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.8835\n",
      "\n",
      "Epoch 00049: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-49_loss-4.4198_val_loss-5.5337.h5\n",
      "Epoch 50/120\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 772s 772ms/step - loss: 4.4154 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 659.3761 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.7733 - val_loss: 5.8489 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.2214\n",
      "\n",
      "Epoch 00050: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-50_loss-4.4154_val_loss-5.8489.h5\n",
      "Epoch 51/120\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 767s 767ms/step - loss: 4.2077 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 658.9215 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.5785 - val_loss: 5.4770 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.8524\n",
      "\n",
      "Epoch 00051: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-51_loss-4.2077_val_loss-5.4770.h5\n",
      "Epoch 52/120\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 779s 779ms/step - loss: 4.1858 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 649.0753 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.5594 - val_loss: 5.4432 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.8214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00052: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-52_loss-4.1858_val_loss-5.4432.h5\n",
      "Epoch 53/120\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 767s 767ms/step - loss: 4.1120 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 638.5220 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4884 - val_loss: 5.4218 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.8028\n",
      "\n",
      "Epoch 00053: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-53_loss-4.1120_val_loss-5.4218.h5\n",
      "Epoch 54/120\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 754s 754ms/step - loss: 4.1261 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 660.0350 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.5052 - val_loss: 5.4964 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.8801\n",
      "\n",
      "Epoch 00054: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-54_loss-4.1261_val_loss-5.4964.h5\n",
      "Epoch 55/120\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 760s 760ms/step - loss: 4.1058 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 662.5776 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4877 - val_loss: 5.4488 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.8353\n",
      "\n",
      "Epoch 00055: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-55_loss-4.1058_val_loss-5.4488.h5\n",
      "Epoch 56/120\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 776s 776ms/step - loss: 4.0685 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 671.0572 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4531 - val_loss: 5.5534 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9426\n",
      "\n",
      "Epoch 00056: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-56_loss-4.0685_val_loss-5.5534.h5\n",
      "Epoch 57/120\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 783s 783ms/step - loss: 4.0954 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 670.9079 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4827 - val_loss: 5.4807 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.8727\n",
      "\n",
      "Epoch 00057: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-57_loss-4.0954_val_loss-5.4807.h5\n",
      "Epoch 58/120\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 766s 766ms/step - loss: 4.0517 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 661.8052 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4418 - val_loss: 5.5055 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9003\n",
      "\n",
      "Epoch 00058: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-58_loss-4.0517_val_loss-5.5055.h5\n",
      "Epoch 59/120\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 781s 781ms/step - loss: 4.0941 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 658.4141 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4869 - val_loss: 5.5047 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9023\n",
      "\n",
      "Epoch 00059: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-59_loss-4.0941_val_loss-5.5047.h5\n",
      "Epoch 60/120\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 785s 785ms/step - loss: 4.0516 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 675.8936 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4471 - val_loss: 5.4669 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.8672\n",
      "\n",
      "Epoch 00060: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-60_loss-4.0516_val_loss-5.4669.h5\n",
      "Epoch 61/120\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 785s 785ms/step - loss: 4.0605 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 688.3913 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4586 - val_loss: 5.5149 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9179\n",
      "\n",
      "Epoch 00061: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-61_loss-4.0605_val_loss-5.5149.h5\n",
      "Epoch 62/120\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 779s 779ms/step - loss: 4.0341 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 677.9767 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4350 - val_loss: 5.4565 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.8623\n",
      "\n",
      "Epoch 00062: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-62_loss-4.0341_val_loss-5.4565.h5\n",
      "Epoch 63/120\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 778s 778ms/step - loss: 4.0013 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 701.6148 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4049 - val_loss: 5.5005 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9089\n",
      "\n",
      "Epoch 00063: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-63_loss-4.0013_val_loss-5.5005.h5\n",
      "Epoch 64/120\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 774s 774ms/step - loss: 4.0477 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 677.5243 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4541 - val_loss: 5.5429 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9540\n",
      "\n",
      "Epoch 00064: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-64_loss-4.0477_val_loss-5.5429.h5\n",
      "Epoch 65/120\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 778s 778ms/step - loss: 4.0213 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 694.1044 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4303 - val_loss: 5.5285 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00065: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-65_loss-4.0213_val_loss-5.5285.h5\n",
      "Epoch 66/120\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 792s 792ms/step - loss: 4.0102 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 694.2826 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4219 - val_loss: 5.4600 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.8765\n",
      "\n",
      "Epoch 00066: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-66_loss-4.0102_val_loss-5.4600.h5\n",
      "Epoch 67/120\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 768s 768ms/step - loss: 4.0024 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 703.2926 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4168 - val_loss: 5.5234 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9426\n",
      "\n",
      "Epoch 00067: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-67_loss-4.0024_val_loss-5.5234.h5\n",
      "Epoch 68/120\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 782s 782ms/step - loss: 4.0045 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 707.9143 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4214 - val_loss: 5.6100 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 4.0319\n",
      "\n",
      "Epoch 00068: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-68_loss-4.0045_val_loss-5.6100.h5\n",
      "Epoch 69/120\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 766s 766ms/step - loss: 4.0019 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 706.2963 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4216 - val_loss: 5.4978 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9223\n",
      "\n",
      "Epoch 00069: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-69_loss-4.0019_val_loss-5.4978.h5\n",
      "Epoch 70/120\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 756s 756ms/step - loss: 3.9883 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 710.3407 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4106 - val_loss: 5.5726 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9998\n",
      "\n",
      "Epoch 00070: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-70_loss-3.9883_val_loss-5.5726.h5\n",
      "Epoch 71/120\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 780s 780ms/step - loss: 3.9713 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 710.4622 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3951 - val_loss: 5.5241 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9516\n",
      "\n",
      "Epoch 00071: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-71_loss-3.9713_val_loss-5.5241.h5\n",
      "Epoch 72/120\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 762s 762ms/step - loss: 3.9960 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 728.8850 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4200 - val_loss: 5.5085 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9363\n",
      "\n",
      "Epoch 00072: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-72_loss-3.9960_val_loss-5.5085.h5\n",
      "Epoch 73/120\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 759s 759ms/step - loss: 3.9706 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 701.7068 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3950 - val_loss: 5.4890 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9170\n",
      "\n",
      "Epoch 00073: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-73_loss-3.9706_val_loss-5.4890.h5\n",
      "Epoch 74/120\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 781s 781ms/step - loss: 3.9715 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 708.2945 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3961 - val_loss: 5.5151 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9434\n",
      "\n",
      "Epoch 00074: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-74_loss-3.9715_val_loss-5.5151.h5\n",
      "Epoch 75/120\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 784s 784ms/step - loss: 3.9634 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 708.6646 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3883 - val_loss: 5.5352 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9638\n",
      "\n",
      "Epoch 00075: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-75_loss-3.9634_val_loss-5.5352.h5\n",
      "Epoch 76/120\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 757s 757ms/step - loss: 3.9512 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 702.6543 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3764 - val_loss: 5.4796 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9084\n",
      "\n",
      "Epoch 00076: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-76_loss-3.9512_val_loss-5.4796.h5\n",
      "Epoch 77/120\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 753s 753ms/step - loss: 3.9810 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 722.4639 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4064 - val_loss: 5.4821 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9112\n",
      "\n",
      "Epoch 00077: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-77_loss-3.9810_val_loss-5.4821.h5\n",
      "Epoch 78/120\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 774s 774ms/step - loss: 3.9542 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 721.2110 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3798 - val_loss: 5.4886 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00078: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-78_loss-3.9542_val_loss-5.4886.h5\n",
      "Epoch 79/120\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 754s 754ms/step - loss: 3.9309 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 717.0146 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3568 - val_loss: 5.5386 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9683\n",
      "\n",
      "Epoch 00079: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-79_loss-3.9309_val_loss-5.5386.h5\n",
      "Epoch 80/120\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 778s 778ms/step - loss: 3.9616 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 725.5602 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3878 - val_loss: 5.4993 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9292\n",
      "\n",
      "Epoch 00080: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-80_loss-3.9616_val_loss-5.4993.h5\n",
      "Epoch 81/120\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 776s 776ms/step - loss: 3.9471 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 719.7425 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3736 - val_loss: 5.4909 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9210\n",
      "\n",
      "Epoch 00081: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-81_loss-3.9471_val_loss-5.4909.h5\n",
      "Epoch 82/120\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 775s 775ms/step - loss: 3.9657 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 711.9330 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3924 - val_loss: 5.4855 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9159\n",
      "\n",
      "Epoch 00082: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-82_loss-3.9657_val_loss-5.4855.h5\n",
      "Epoch 83/120\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 776s 776ms/step - loss: 3.9893 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 723.1916 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.4162 - val_loss: 5.4743 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9049\n",
      "\n",
      "Epoch 00083: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-83_loss-3.9893_val_loss-5.4743.h5\n",
      "Epoch 84/120\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 781s 781ms/step - loss: 3.9361 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 714.5857 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3633 - val_loss: 5.5082 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9391\n",
      "\n",
      "Epoch 00084: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-84_loss-3.9361_val_loss-5.5082.h5\n",
      "Epoch 85/120\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 772s 772ms/step - loss: 3.9661 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 711.5669 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3936 - val_loss: 5.5106 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9418\n",
      "\n",
      "Epoch 00085: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-85_loss-3.9661_val_loss-5.5106.h5\n",
      "Epoch 86/120\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 778s 778ms/step - loss: 3.9477 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 717.4381 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3754 - val_loss: 5.5392 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9706\n",
      "\n",
      "Epoch 00086: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-86_loss-3.9477_val_loss-5.5392.h5\n",
      "Epoch 87/120\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 782s 782ms/step - loss: 3.9406 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 715.6390 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3687 - val_loss: 5.5023 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9340\n",
      "\n",
      "Epoch 00087: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-87_loss-3.9406_val_loss-5.5023.h5\n",
      "Epoch 88/120\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 777s 777ms/step - loss: 3.9426 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 702.0334 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3709 - val_loss: 5.5099 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9419\n",
      "\n",
      "Epoch 00088: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-88_loss-3.9426_val_loss-5.5099.h5\n",
      "Epoch 89/120\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 773s 773ms/step - loss: 3.9542 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 708.0052 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3828 - val_loss: 5.4968 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9290\n",
      "\n",
      "Epoch 00089: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-89_loss-3.9542_val_loss-5.4968.h5\n",
      "Epoch 90/120\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 779s 779ms/step - loss: 3.9540 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 716.6989 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3828 - val_loss: 5.4946 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9271\n",
      "\n",
      "Epoch 00090: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-90_loss-3.9540_val_loss-5.4946.h5\n",
      "Epoch 91/120\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 786s 786ms/step - loss: 3.9566 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 712.9129 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3857 - val_loss: 5.4974 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00091: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-91_loss-3.9566_val_loss-5.4974.h5\n",
      "Epoch 92/120\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 796s 796ms/step - loss: 3.9386 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 724.6492 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3679 - val_loss: 5.5076 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9406\n",
      "\n",
      "Epoch 00092: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-92_loss-3.9386_val_loss-5.5076.h5\n",
      "Epoch 93/120\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 780s 780ms/step - loss: 3.9429 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 732.6322 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3724 - val_loss: 5.5045 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9378\n",
      "\n",
      "Epoch 00093: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-93_loss-3.9429_val_loss-5.5045.h5\n",
      "Epoch 94/120\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 771s 771ms/step - loss: 3.9382 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 715.0725 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3681 - val_loss: 5.4998 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9334\n",
      "\n",
      "Epoch 00094: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-94_loss-3.9382_val_loss-5.4998.h5\n",
      "Epoch 95/120\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 769s 769ms/step - loss: 3.9335 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 722.0165 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3636 - val_loss: 5.4918 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9257\n",
      "\n",
      "Epoch 00095: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-95_loss-3.9335_val_loss-5.4918.h5\n",
      "Epoch 96/120\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 784s 784ms/step - loss: 3.9224 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 729.0792 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3528 - val_loss: 5.4882 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9223\n",
      "\n",
      "Epoch 00096: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-96_loss-3.9224_val_loss-5.4882.h5\n",
      "Epoch 97/120\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 788s 788ms/step - loss: 3.9434 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 726.4495 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3740 - val_loss: 5.4961 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9305\n",
      "\n",
      "Epoch 00097: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-97_loss-3.9434_val_loss-5.4961.h5\n",
      "Epoch 98/120\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 769s 769ms/step - loss: 3.9266 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 714.5625 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3576 - val_loss: 5.4813 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9159\n",
      "\n",
      "Epoch 00098: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-98_loss-3.9266_val_loss-5.4813.h5\n",
      "Epoch 99/120\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 774s 774ms/step - loss: 3.9277 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 717.5795 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3589 - val_loss: 5.4733 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9083\n",
      "\n",
      "Epoch 00099: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-99_loss-3.9277_val_loss-5.4733.h5\n",
      "Epoch 100/120\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 754s 754ms/step - loss: 3.9390 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 728.1354 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3704 - val_loss: 5.4924 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9276\n",
      "\n",
      "Epoch 00100: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-100_loss-3.9390_val_loss-5.4924.h5\n",
      "Epoch 101/120\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 753s 753ms/step - loss: 3.9094 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 722.7322 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3411 - val_loss: 5.5151 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9505\n",
      "\n",
      "Epoch 00101: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-101_loss-3.9094_val_loss-5.5151.h5\n",
      "Epoch 102/120\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 776s 776ms/step - loss: 3.9337 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 717.2828 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3657 - val_loss: 5.4900 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9257\n",
      "\n",
      "Epoch 00102: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-102_loss-3.9337_val_loss-5.4900.h5\n",
      "Epoch 103/120\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 771s 771ms/step - loss: 3.9122 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 726.2356 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3444 - val_loss: 5.4922 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9282\n",
      "\n",
      "Epoch 00103: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-103_loss-3.9122_val_loss-5.4922.h5\n",
      "Epoch 104/120\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 780s 780ms/step - loss: 3.9392 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 725.7713 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3717 - val_loss: 5.4716 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00104: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-104_loss-3.9392_val_loss-5.4716.h5\n",
      "Epoch 105/120\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 772s 772ms/step - loss: 3.9608 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 721.2113 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3936 - val_loss: 5.5002 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9367\n",
      "\n",
      "Epoch 00105: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-105_loss-3.9608_val_loss-5.5002.h5\n",
      "Epoch 106/120\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 759s 759ms/step - loss: 3.9651 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 724.5430 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3981 - val_loss: 5.4869 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9236\n",
      "\n",
      "Epoch 00106: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-106_loss-3.9651_val_loss-5.4869.h5\n",
      "Epoch 107/120\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 755s 755ms/step - loss: 3.9117 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 722.4982 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3450 - val_loss: 5.4974 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9344\n",
      "\n",
      "Epoch 00107: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-107_loss-3.9117_val_loss-5.4974.h5\n",
      "Epoch 108/120\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 763s 763ms/step - loss: 3.9235 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 721.1136 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3571 - val_loss: 5.4972 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9345\n",
      "\n",
      "Epoch 00108: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-108_loss-3.9235_val_loss-5.4972.h5\n",
      "Epoch 109/120\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 782s 782ms/step - loss: 3.9234 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 720.3073 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3573 - val_loss: 5.5066 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9442\n",
      "\n",
      "Epoch 00109: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-109_loss-3.9234_val_loss-5.5066.h5\n",
      "Epoch 110/120\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 781s 781ms/step - loss: 3.9439 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 720.3443 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3779 - val_loss: 5.4852 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9231\n",
      "\n",
      "Epoch 00110: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-110_loss-3.9439_val_loss-5.4852.h5\n",
      "Epoch 111/120\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 767s 767ms/step - loss: 3.9490 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 713.4125 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3834 - val_loss: 5.4952 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9333\n",
      "\n",
      "Epoch 00111: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-111_loss-3.9490_val_loss-5.4952.h5\n",
      "Epoch 112/120\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 754s 754ms/step - loss: 3.8986 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 730.6512 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.3332 - val_loss: 5.5007 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 3.9390\n",
      "\n",
      "Epoch 00112: saving model to ../trained_weights/SSD512_City_to_foggy0_01_resize_400_800/current/pool2_loss_weights_0_000005/epoch-112_loss-3.8986_val_loss-5.5007.h5\n",
      "Epoch 113/120\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 1e-05.\n",
      " 166/1000 [===>..........................] - ETA: 10:00 - loss: 3.8597 - pool1_GAP_substract_loss: 0.0000e+00 - pool2_GAP_substract_loss: 744.4009 - pool3_GAP_substract_loss: 0.0000e+00 - predictions_loss: 2.2943"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ea67b764e796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_epoch = 0\n",
    "final_epoch = 120\n",
    "steps_per_epoch = 1000\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Set the generator for the val_dataset or train_dataset predictions.\n",
    "\n",
    "predict_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=None,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'filenames',\n",
    "                                                  'inverse_transform',\n",
    "                                                  'original_images',\n",
    "                                                  'original_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "# 2: Generate samples.\n",
    "\n",
    "batch_images, batch_filenames, batch_inverse_transforms, batch_original_images, batch_original_labels = next(predict_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_images, batch_filenames, batch_inverse_transforms, batch_original_images, batch_original_labels = next(predict_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "print(\"Image:\", batch_filenames[i])\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, n_classes+1)).tolist()\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.imshow(batch_images[0][i])\n",
    "plt.show()\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.imshow(batch_images[1][i])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  # Which batch item to look at\n",
    "\n",
    "print(\"Image:\", batch_filenames[i])\n",
    "print()\n",
    "print(\"Ground truth boxes:\\n\")\n",
    "print(np.array(batch_original_labels[i]))\n",
    "\n",
    "# 3: Make predictions.\n",
    "\n",
    "y_pred = model.predict(batch_images)[-1]\n",
    "\n",
    "# Now let's decode the raw predictions in `y_pred`.\n",
    "\n",
    "# Had we created the model in 'inference' or 'inference_fast' mode,\n",
    "# then the model's final layer would be a `DecodeDetections` layer and\n",
    "# `y_pred` would already contain the decoded predictions,\n",
    "# but since we created the model in 'training' mode,\n",
    "# the model outputs raw predictions that still need to be decoded and filtered.\n",
    "# This is what the `decode_detections()` function is for.\n",
    "# It does exactly what the `DecodeDetections` layer would do,\n",
    "# but using Numpy instead of TensorFlow (i.e. on the CPU instead of the GPU).\n",
    "\n",
    "# `decode_detections()` with default argument values follows the procedure of the original SSD implementation:\n",
    "# First, a very low confidence threshold of 0.01 is applied to filter out the majority of the predicted boxes,\n",
    "# then greedy non-maximum suppression is performed per class with an intersection-over-union threshold of 0.45,\n",
    "# and out of what is left after that, the top 200 highest confidence boxes are returned.\n",
    "# Those settings are for precision-recall scoring purposes though.\n",
    "# In order to get some usable final predictions, we'll set the confidence threshold much higher, e.g. to 0.5,\n",
    "# since we're only interested in the very confident predictions.\n",
    "\n",
    "# 4: Decode the raw predictions in `y_pred`.\n",
    "\n",
    "y_pred_decoded = decode_detections(y_pred,\n",
    "                                   confidence_thresh=0.35,\n",
    "                                   iou_threshold=0.4,\n",
    "                                   top_k=200,\n",
    "                                   normalize_coords=normalize_coords,\n",
    "                                   img_height=img_height,\n",
    "                                   img_width=img_width)\n",
    "\n",
    "# We made the predictions on the resized images,\n",
    "# but we'd like to visualize the outcome on the original input images,\n",
    "# so we'll convert the coordinates accordingly.\n",
    "# Don't worry about that opaque `apply_inverse_transforms()` function below,\n",
    "# in this simple case it just applies `(* original_image_size / resized_image_size)` to the box coordinates.\n",
    "\n",
    "# 5: Convert the predictions for the original image.\n",
    "\n",
    "y_pred_decoded_inv = apply_inverse_transforms(y_pred_decoded, batch_inverse_transforms)\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "print(\"Predicted boxes:\\n\")\n",
    "print('   class   conf xmin   ymin   xmax   ymax')\n",
    "print(y_pred_decoded_inv[i])\n",
    "\n",
    "# Finally, let's draw the predicted boxes onto the image.\n",
    "# Each predicted box says its confidence next to the category name.\n",
    "# The ground truth boxes are also drawn onto the image in green for comparison.\n",
    "\n",
    "# 5: Draw the predicted boxes onto the image\n",
    "\n",
    "# Set the colors for the bounding boxes\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, n_classes+1)).tolist()\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.imshow(batch_original_images[i])\n",
    "\n",
    "current_axis = plt.gca()\n",
    "\n",
    "for box in batch_original_labels[i]:\n",
    "    xmin = box[1]\n",
    "    ymin = box[2]\n",
    "    xmax = box[3]\n",
    "    ymax = box[4]\n",
    "    label = '{}'.format(classes[int(box[0])])\n",
    "    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color='green', fill=False, linewidth=2))\n",
    "    current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor': 'green', 'alpha': 1.0})\n",
    "\n",
    "# for box in y_pred_decoded_inv[i]:\n",
    "#     xmin = box[2]\n",
    "#     ymin = box[3]\n",
    "#     xmax = box[4]\n",
    "#     ymax = box[5]\n",
    "#     color = colors[int(box[0])]\n",
    "#     label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
    "#     current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))\n",
    "#     current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor': color, 'alpha': 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
