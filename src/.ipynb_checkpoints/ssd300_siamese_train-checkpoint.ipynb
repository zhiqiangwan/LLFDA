{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import glob\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd300_Siamese import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation, SSDDataAugmentation_Siamese\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "\n",
    "img_height = 300 # Height of the model input images\n",
    "img_width = 300 # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [123, 117, 104] # Per-channel mean of images. Do not change if use any of the pre-trained weights.\n",
    "# The color channel order in the original SSD is BGR,\n",
    "# so we'll have the model reverse the color channel order of the input images.\n",
    "swap_channels = [2, 1, 0]\n",
    "# The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets\n",
    "# scales_pascal = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05]\n",
    "# The anchor box scaling factors used in the original SSD300 for the MS COCO datasets\n",
    "scales_coco = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05]\n",
    "scales = scales_coco\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [8, 16, 32, 64, 100, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "# The offsets of the first anchor box center points from the top and left borders of the image\n",
    "# as a fraction of the step size for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "# The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "variances = [0.1, 0.1, 0.2, 0.2]\n",
    "normalize_coords = True\n",
    "Model_Build = 'New_Model'  # 'Load_Model'\n",
    "Optimizer_Type = 'SGD'  # 'Adam' #  \n",
    "batch_size = 16  # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "# alpha_distance =  0.001  # Coefficient for the distance between the source and target feature maps.\n",
    "loss_weights = [0.000001, 0.000001, 0.000001] + [0.0, 0.0, 0.0, 0.0, 0.0, 0.0] + [1.0]\n",
    "Source_Only = False\n",
    "\n",
    "# 'City_to_foggy0_02_resize_600_1200' # 'SIM10K_to_VOC07'  #'SIM10K'  # 'Cityscapes_foggy_beta_0_01'  #\n",
    "DatasetName = 'City_to_foggy0_01_resize_600_1200'\n",
    "processed_dataset_path = './processed_dataset_h5/' + DatasetName\n",
    "if not os.path.exists(processed_dataset_path):\n",
    "    os.makedirs(processed_dataset_path)\n",
    "\n",
    "if len(glob.glob(os.path.join(processed_dataset_path, '*.h5'))):\n",
    "    Dataset_Build = 'Load_Dataset'\n",
    "else:\n",
    "    Dataset_Build = 'New_Dataset'\n",
    "\n",
    "if DatasetName == 'City_to_foggy0_01_resize_600_1200':\n",
    "    resize_image_to = (600, 1200)\n",
    "    # Introduction of PascalVOC: https://arleyzhang.github.io/articles/1dc20586/\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/CITYSCAPES_beta_0_01/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/CITYSCAPES_beta_0_01/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "    test_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_target.txt'\n",
    "    test_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/test.txt'\n",
    "    # Our model will produce predictions for these classes.\n",
    "    classes = ['background',\n",
    "               'person', 'rider', 'car', 'truck',\n",
    "               'bus', 'train', 'motorcycle', 'bicycle']\n",
    "    train_classes = classes\n",
    "    train_include_classes = 'all'\n",
    "    val_classes = classes\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'City_to_foggy0_02_resize_600_1200':\n",
    "    resize_image_to = (600, 1200)\n",
    "    # Introduction of PascalVOC: https://arleyzhang.github.io/articles/1dc20586/\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "    test_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_target.txt'\n",
    "    test_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/test.txt'\n",
    "    # Our model will produce predictions for these classes.\n",
    "    classes = ['background',\n",
    "               'person', 'rider', 'car', 'truck',\n",
    "               'bus', 'train', 'motorcycle', 'bicycle']\n",
    "    train_classes = classes\n",
    "    train_include_classes = 'all'\n",
    "    val_classes = classes\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'Cityscapes_foggy_beta_0_01':\n",
    "    resize_image_to = (300, 600)\n",
    "    # Introduction of PascalVOC: https://arleyzhang.github.io/articles/1dc20586/\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/CITYSCAPES_beta_0_01/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/CITYSCAPES_beta_0_01/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "    test_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_target.txt'\n",
    "    test_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/test.txt'\n",
    "    classes = ['background',\n",
    "               'person', 'rider', 'car', 'truck',\n",
    "               'bus', 'train', 'motorcycle', 'bicycle']\n",
    "    train_classes = classes\n",
    "    train_include_classes = 'all'\n",
    "    val_classes = classes\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'SIM10K':\n",
    "    resize_image_to = (300, 600)\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/SIM10K/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/val_data_for_SIM10K_to_cityscapes/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/SIM10K/Annotations'\n",
    "    test_annotation_dir = '../../datasets/val_data_for_SIM10K_to_cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/SIM10K/ImageSets/Main/trainval10k.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    test_target_image_set_filename = '../../datasets/val_data_for_SIM10K_to_cityscapes/ImageSets/Main/test.txt'\n",
    "\n",
    "    classes = ['background', 'car']  # Our model will produce predictions for these classes.\n",
    "    train_classes = ['background', 'car', 'motorbike', 'person']  # The train_source dataset contains these classes.\n",
    "    train_include_classes = [train_classes.index(one_class) for one_class in classes[1:]]\n",
    "    # The test_target dataset contains these classes.\n",
    "    val_classes = ['background', 'car']\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "    \n",
    "elif DatasetName == 'SIM10K_to_VOC07':\n",
    "    resize_image_to = (300, 600)\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/SIM10K/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/VOCdevkit/VOC2007/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/VOCdevkit/VOC2007/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/SIM10K/Annotations'\n",
    "    test_annotation_dir = '../../datasets/VOCdevkit/VOC2007/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/SIM10K/ImageSets/Main/trainval10k.txt'\n",
    "    # The trainset of VOC which has 'car' object is used as train_target.\n",
    "    train_target_image_set_filename = '../../datasets/VOCdevkit/VOC2007_CAR/ImageSets/Main/train_target.txt'\n",
    "    # The valset of VOC which has 'car' object is used as test.\n",
    "    test_target_image_set_filename = '../../datasets/VOCdevkit/VOC2007_CAR/ImageSets/Main/test.txt'\n",
    "\n",
    "    classes = ['background', 'car']  # Our model will produce predictions for these classes.\n",
    "    train_classes = ['background', 'car', 'motorbike', 'person']  # The train_source dataset contains these classes.\n",
    "    train_include_classes = [train_classes.index(one_class) for one_class in classes[1:]]\n",
    "    # The test_target dataset contains these classes.\n",
    "    val_classes = ['background', 'car',\n",
    "                   'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                   'bottle', 'bus', 'cat',\n",
    "                   'chair', 'cow', 'diningtable', 'dog',\n",
    "                   'horse', 'motorbike', 'person', 'pottedplant',\n",
    "                   'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "    val_include_classes = [val_classes.index(one_class) for one_class in classes[1:]]\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "    \n",
    "else:\n",
    "    raise ValueError('Undefined dataset name.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Model_Build == 'New_Model':\n",
    "    # 1: Build the Keras model.\n",
    "\n",
    "    K.clear_session()  # Clear previous models from memory.\n",
    "\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "    model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                    n_classes=n_classes,\n",
    "                    mode='training',\n",
    "                    l2_regularization=0.0005,\n",
    "                    scales=scales,\n",
    "                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                    steps=steps,\n",
    "                    offsets=offsets,\n",
    "                    clip_boxes=clip_boxes,\n",
    "                    variances=variances,\n",
    "                    normalize_coords=normalize_coords,\n",
    "                    subtract_mean=mean_color,\n",
    "                    swap_channels=swap_channels)\n",
    "\n",
    "    # 2: Load some weights into the model.\n",
    "\n",
    "    # TODO: Set the path to the weights you want to load.\n",
    "    weights_path = '../trained_weights/VGG_ILSVRC_16_layers_fc_reduced.h5'\n",
    "\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    # 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "    #    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "    #    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "    if Optimizer_Type == 'SGD':\n",
    "        Optimizer = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n",
    "    elif Optimizer_Type == 'Adam':\n",
    "        Optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    else:\n",
    "        raise ValueError('Undefined Optimizer_Type.')\n",
    "\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "    if Source_Only:\n",
    "        model.compile(optimizer=Optimizer, loss={'pool1_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "                                                 'pool2_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "                                                 'pool3_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "                                                 'conv4_3_norm_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "                                                 'fc7_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "                                                 'conv6_2_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "                                                 'conv7_2_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "                                                 'conv8_2_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "                                                 'conv9_2_GAP_substract': ssd_loss.compute_distance_loss_source_only,\n",
    "                                                 'predictions': ssd_loss.compute_loss},\n",
    "                      loss_weights={'pool1_GAP_substract': loss_weights[0],\n",
    "                                    'pool2_GAP_substract': loss_weights[1],\n",
    "                                    'pool3_GAP_substract': loss_weights[2],\n",
    "                                    'conv4_3_norm_GAP_substract': loss_weights[3],\n",
    "                                    'fc7_GAP_substract': loss_weights[4],\n",
    "                                    'conv6_2_GAP_substract': loss_weights[5],\n",
    "                                    'conv7_2_GAP_substract': loss_weights[6],\n",
    "                                    'conv8_2_GAP_substract': loss_weights[7],\n",
    "                                    'conv9_2_GAP_substract': loss_weights[8],\n",
    "                                    'predictions': loss_weights[9]})\n",
    "    else:\n",
    "        model.compile(optimizer=Optimizer, loss={'pool1_GAP_substract': ssd_loss.compute_distance_loss,\n",
    "                                                 'pool2_GAP_substract': ssd_loss.compute_distance_loss,\n",
    "                                                 'pool3_GAP_substract': ssd_loss.compute_distance_loss,\n",
    "                                                 'conv4_3_norm_GAP_substract': ssd_loss.compute_distance_loss,\n",
    "                                                 'fc7_GAP_substract': ssd_loss.compute_distance_loss,\n",
    "                                                 'conv6_2_GAP_substract': ssd_loss.compute_distance_loss,\n",
    "                                                 'conv7_2_GAP_substract': ssd_loss.compute_distance_loss,\n",
    "                                                 'conv8_2_GAP_substract': ssd_loss.compute_distance_loss,\n",
    "                                                 'conv9_2_GAP_substract': ssd_loss.compute_distance_loss,\n",
    "                                                 'predictions': ssd_loss.compute_loss},\n",
    "                      loss_weights={'pool1_GAP_substract': loss_weights[0],\n",
    "                                    'pool2_GAP_substract': loss_weights[1],\n",
    "                                    'pool3_GAP_substract': loss_weights[2],\n",
    "                                    'conv4_3_norm_GAP_substract': loss_weights[3],\n",
    "                                    'fc7_GAP_substract': loss_weights[4],\n",
    "                                    'conv6_2_GAP_substract': loss_weights[5],\n",
    "                                    'conv7_2_GAP_substract': loss_weights[6],\n",
    "                                    'conv8_2_GAP_substract': loss_weights[7],\n",
    "                                    'conv9_2_GAP_substract': loss_weights[8],\n",
    "                                    'predictions': loss_weights[9]})\n",
    "              \n",
    "elif Model_Build == 'Load_Model':\n",
    "    # TODO: Set the path to the `.h5` file of the model to be loaded.\n",
    "    model_path = '../trained_weights/VGG_ssd300_Siamese_Cityscapes/epoch-23_loss-5.2110_val_loss-6.7452.h5'\n",
    "\n",
    "    # We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "    K.clear_session()  # Clear previous models from memory.\n",
    "\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "    model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                                   'L2Normalization': L2Normalization,\n",
    "                                                   'compute_loss': ssd_loss.compute_loss,\n",
    "                                                   'compute_distance_loss': ssd_loss.compute_distance_loss})\n",
    "else:\n",
    "    raise ValueError('Undefined Model_Build. Model_Build should be New_Model  or Load_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source labels: 100%|██████████| 2966/2966 [00:00<00:00, 5024.66it/s]\n",
      "Loading source image IDs: 100%|██████████| 2966/2966 [00:00<00:00, 11438.33it/s]\n",
      "Loading target image IDs: 100%|██████████| 2966/2966 [00:00<00:00, 10830.11it/s]\n",
      "Loading evaluation-neutrality annotations: 100%|██████████| 2966/2966 [00:00<00:00, 8333.09it/s]\n",
      "Loading source labels: 100%|██████████| 493/493 [00:00<00:00, 4590.44it/s]\n",
      "Loading source image IDs: 100%|██████████| 493/493 [00:00<00:00, 5840.66it/s]\n",
      "Loading target image IDs: 0it [00:00, ?it/s]\n",
      "Loading evaluation-neutrality annotations: 100%|██████████| 493/493 [00:00<00:00, 7122.48it/s]\n"
     ]
    }
   ],
   "source": [
    "if Dataset_Build == 'New_Dataset':\n",
    "    # 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "    # Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "    train_dataset = DataGenerator(dataset='train', load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "    val_dataset = DataGenerator(dataset='val', load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "\n",
    "    # 2: Parse the image and label lists for the training and validation datasets. This can take a while.\n",
    "    # images_dirs, image_set_filenames, and annotations_dirs should have the same length\n",
    "    train_dataset.parse_xml(images_dirs=[train_source_images_dir],\n",
    "                            target_images_dirs=[train_target_images_dir],\n",
    "                            image_set_filenames=[train_source_image_set_filename],\n",
    "                            target_image_set_filenames=[train_target_image_set_filename],\n",
    "                            annotations_dirs=[train_annotation_dir],\n",
    "                            classes=train_classes,\n",
    "                            include_classes=train_include_classes,\n",
    "                            exclude_truncated=False,\n",
    "                            exclude_difficult=False,\n",
    "                            ret=False)\n",
    "\n",
    "    val_dataset.parse_xml(images_dirs=[test_target_images_dir],\n",
    "                          image_set_filenames=[test_target_image_set_filename],\n",
    "                          annotations_dirs=[test_annotation_dir],\n",
    "                          classes=val_classes,\n",
    "                          include_classes=val_include_classes,\n",
    "                          exclude_truncated=False,\n",
    "                          exclude_difficult=True,\n",
    "                          ret=False)\n",
    "\n",
    "    # Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
    "    # speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
    "    # option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
    "    # want to create HDF5 datasets, comment out the subsequent two function calls.\n",
    "\n",
    "    # After create these h5 files, if you have resized the input image, you need to reload these files. Otherwise,\n",
    "    # the images and the labels will not change.\n",
    "\n",
    "    train_dataset.create_hdf5_dataset(file_path=os.path.join(processed_dataset_path, 'dataset_train.h5'),\n",
    "                                      resize=resize_image_to,\n",
    "                                      variable_image_size=True,\n",
    "                                      verbose=True)\n",
    "\n",
    "    val_dataset.create_hdf5_dataset(file_path=os.path.join(processed_dataset_path, 'dataset_test.h5'),\n",
    "                                    resize=False,\n",
    "                                    variable_image_size=True,\n",
    "                                    verbose=True)\n",
    "\n",
    "    train_dataset = DataGenerator(dataset='train',\n",
    "                                  load_images_into_memory=False,\n",
    "                                  hdf5_dataset_path=os.path.join(processed_dataset_path, 'dataset_train.h5'),\n",
    "                                  filenames=train_source_image_set_filename,\n",
    "                                  target_filenames=train_target_image_set_filename,\n",
    "                                  filenames_type='text',\n",
    "                                  images_dir=train_source_images_dir,\n",
    "                                  target_images_dir=train_target_images_dir)\n",
    "\n",
    "    val_dataset = DataGenerator(dataset='val',\n",
    "                                load_images_into_memory=False,\n",
    "                                hdf5_dataset_path=os.path.join(processed_dataset_path, 'dataset_test.h5'),\n",
    "                                filenames=test_target_image_set_filename,\n",
    "                                filenames_type='text',\n",
    "                                images_dir=test_target_images_dir)\n",
    "\n",
    "elif Dataset_Build == 'Load_Dataset':\n",
    "    # 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "    # Load dataset from the created h5 file.\n",
    "    train_dataset = DataGenerator(dataset='train',\n",
    "                                  load_images_into_memory=False,\n",
    "                                  hdf5_dataset_path=os.path.join(processed_dataset_path, 'dataset_train.h5'),\n",
    "                                  filenames=train_source_image_set_filename,\n",
    "                                  target_filenames=train_target_image_set_filename,\n",
    "                                  filenames_type='text',\n",
    "                                  images_dir=train_source_images_dir,\n",
    "                                  target_images_dir=train_target_images_dir)\n",
    "\n",
    "    val_dataset = DataGenerator(dataset='val',\n",
    "                                load_images_into_memory=False,\n",
    "                                hdf5_dataset_path=os.path.join(processed_dataset_path, 'dataset_test.h5'),\n",
    "                                filenames=test_target_image_set_filename,\n",
    "                                filenames_type='text',\n",
    "                                images_dir=test_target_images_dir)\n",
    "\n",
    "else:\n",
    "    raise ValueError('Undefined Dataset_Build. Dataset_Build should be New_Dataset or Load_Dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t  2966\n",
      "Number of images in the validation dataset:\t   493\n"
     ]
    }
   ],
   "source": [
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation_Siamese(img_height=img_height,\n",
    "                                                    img_width=img_width)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('conv4_3_norm_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('fc7_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv6_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv7_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv8_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv9_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "# The input image and label are first processed by transformations. Then, the label will be further encoded by\n",
    "# ssd_input_encoder. The encoded labels are classId and offset to each anchor box.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    if epoch < 2:\n",
    "        return 0.0005\n",
    "    elif epoch < 60:\n",
    "        return 0.001\n",
    "    elif epoch < 100:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00001\n",
    "\n",
    "# def lr_schedule(epoch):\n",
    "#     if epoch < 30:\n",
    "#         return 0.001\n",
    "#     elif epoch < 60:\n",
    "#         return 0.0001\n",
    "#     else:\n",
    "#         return 0.00001\n",
    "\n",
    "# Define model callbacks.\n",
    "checkpoint_path = '../trained_weights/City_to_foggy0_01_resize_600_1200/current/pool123_loss_weights_0_000001'\n",
    "# checkpoint_path = '../trained_weights/current/ssd_augm_beta_0_01_source_only'\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath=os.path.join(checkpoint_path, 'epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5'),\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=False,\n",
    "                                   save_weights_only=True,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "# model_checkpoint.best to the best validation loss from the previous training\n",
    "# model_checkpoint.best = 4.83704\n",
    "\n",
    "csv_logger = CSVLogger(filename=os.path.join(checkpoint_path, 'pool123_loss_weights_0_000001_training_log.csv'),\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule,\n",
    "                                                verbose=1)\n",
    "\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "TensorBoard_monitor = TensorBoard(log_dir=checkpoint_path)\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             learning_rate_scheduler,\n",
    "             terminate_on_nan,\n",
    "             TensorBoard_monitor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1043s 1s/step - loss: 10.2442 - pool1_GAP_substract_loss: 59156.5440 - pool2_GAP_substract_loss: 64297.0490 - pool3_GAP_substract_loss: 39667.7428 - conv4_3_norm_GAP_substract_loss: 6.5856 - fc7_GAP_substract_loss: 7.1857 - conv6_2_GAP_substract_loss: 3.5211 - conv7_2_GAP_substract_loss: 1.5863 - conv8_2_GAP_substract_loss: 3.1936 - conv9_2_GAP_substract_loss: 7.9913 - predictions_loss: 7.0041 - val_loss: 10.1575 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.0958\n",
      "\n",
      "Epoch 00001: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-01_loss-10.2442_val_loss-10.1575.h5\n",
      "Epoch 2/120\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1021s 1s/step - loss: 8.9472 - pool1_GAP_substract_loss: 33318.3671 - pool2_GAP_substract_loss: 20565.7890 - pool3_GAP_substract_loss: 10542.6800 - conv4_3_norm_GAP_substract_loss: 6.1329 - fc7_GAP_substract_loss: 6.6765 - conv6_2_GAP_substract_loss: 4.3740 - conv7_2_GAP_substract_loss: 2.1212 - conv8_2_GAP_substract_loss: 4.1843 - conv9_2_GAP_substract_loss: 12.0553 - predictions_loss: 5.8358 - val_loss: 9.9723 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.9398\n",
      "\n",
      "Epoch 00002: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-02_loss-8.9472_val_loss-9.9723.h5\n",
      "Epoch 3/120\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1406s 1s/step - loss: 8.6689 - pool1_GAP_substract_loss: 25813.4393 - pool2_GAP_substract_loss: 15664.7251 - pool3_GAP_substract_loss: 7193.1315 - conv4_3_norm_GAP_substract_loss: 6.6033 - fc7_GAP_substract_loss: 6.7347 - conv6_2_GAP_substract_loss: 4.2761 - conv7_2_GAP_substract_loss: 2.4411 - conv8_2_GAP_substract_loss: 4.9372 - conv9_2_GAP_substract_loss: 14.6896 - predictions_loss: 5.6155 - val_loss: 9.7419 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.7649\n",
      "\n",
      "Epoch 00003: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-03_loss-8.6689_val_loss-9.7419.h5\n",
      "Epoch 4/120\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 2328s 2s/step - loss: 8.3373 - pool1_GAP_substract_loss: 20787.0420 - pool2_GAP_substract_loss: 11880.6517 - pool3_GAP_substract_loss: 4770.0012 - conv4_3_norm_GAP_substract_loss: 6.8380 - fc7_GAP_substract_loss: 6.5912 - conv6_2_GAP_substract_loss: 4.2731 - conv7_2_GAP_substract_loss: 2.7646 - conv8_2_GAP_substract_loss: 5.9227 - conv9_2_GAP_substract_loss: 17.6645 - predictions_loss: 5.3501 - val_loss: 9.5729 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.6503\n",
      "\n",
      "Epoch 00004: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-04_loss-8.3373_val_loss-9.5729.h5\n",
      "Epoch 5/120\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 2241s 2s/step - loss: 8.0560 - pool1_GAP_substract_loss: 17562.9760 - pool2_GAP_substract_loss: 9988.3703 - pool3_GAP_substract_loss: 3769.3537 - conv4_3_norm_GAP_substract_loss: 7.0241 - fc7_GAP_substract_loss: 6.5362 - conv6_2_GAP_substract_loss: 4.4059 - conv7_2_GAP_substract_loss: 2.9677 - conv8_2_GAP_substract_loss: 6.7523 - conv9_2_GAP_substract_loss: 19.5314 - predictions_loss: 5.1286 - val_loss: 9.6810 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.8113\n",
      "\n",
      "Epoch 00005: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-05_loss-8.0560_val_loss-9.6810.h5\n",
      "Epoch 6/120\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1364s 1s/step - loss: 7.8421 - pool1_GAP_substract_loss: 15321.1842 - pool2_GAP_substract_loss: 8605.9930 - pool3_GAP_substract_loss: 3240.4654 - conv4_3_norm_GAP_substract_loss: 7.4493 - fc7_GAP_substract_loss: 6.8245 - conv6_2_GAP_substract_loss: 4.5541 - conv7_2_GAP_substract_loss: 3.1767 - conv8_2_GAP_substract_loss: 7.5733 - conv9_2_GAP_substract_loss: 20.7703 - predictions_loss: 4.9712 - val_loss: 9.4351 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.6171\n",
      "\n",
      "Epoch 00006: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-06_loss-7.8421_val_loss-9.4351.h5\n",
      "Epoch 7/120\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 2138s 2s/step - loss: 7.6790 - pool1_GAP_substract_loss: 13279.6639 - pool2_GAP_substract_loss: 7349.5495 - pool3_GAP_substract_loss: 2738.6882 - conv4_3_norm_GAP_substract_loss: 7.9725 - fc7_GAP_substract_loss: 6.7069 - conv6_2_GAP_substract_loss: 4.5352 - conv7_2_GAP_substract_loss: 3.3504 - conv8_2_GAP_substract_loss: 7.8895 - conv9_2_GAP_substract_loss: 21.4269 - predictions_loss: 4.8629 - val_loss: 9.2318 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.4642\n",
      "\n",
      "Epoch 00007: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-07_loss-7.6790_val_loss-9.2318.h5\n",
      "Epoch 8/120\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 2377s 2s/step - loss: 7.5375 - pool1_GAP_substract_loss: 12095.0641 - pool2_GAP_substract_loss: 6535.1080 - pool3_GAP_substract_loss: 2351.0802 - conv4_3_norm_GAP_substract_loss: 7.8522 - fc7_GAP_substract_loss: 6.5859 - conv6_2_GAP_substract_loss: 4.4831 - conv7_2_GAP_substract_loss: 3.3023 - conv8_2_GAP_substract_loss: 7.9546 - conv9_2_GAP_substract_loss: 21.6217 - predictions_loss: 4.7737 - val_loss: 9.4296 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.7113\n",
      "\n",
      "Epoch 00008: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-08_loss-7.5375_val_loss-9.4296.h5\n",
      "Epoch 9/120\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 2226s 2s/step - loss: 7.4317 - pool1_GAP_substract_loss: 10949.2757 - pool2_GAP_substract_loss: 5771.9195 - pool3_GAP_substract_loss: 2025.6128 - conv4_3_norm_GAP_substract_loss: 7.9165 - fc7_GAP_substract_loss: 6.5454 - conv6_2_GAP_substract_loss: 4.4074 - conv7_2_GAP_substract_loss: 3.4231 - conv8_2_GAP_substract_loss: 8.2432 - conv9_2_GAP_substract_loss: 21.9372 - predictions_loss: 4.7186 - val_loss: 9.2617 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.5912\n",
      "\n",
      "Epoch 00009: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-09_loss-7.4317_val_loss-9.2617.h5\n",
      "Epoch 10/120\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1758s 2s/step - loss: 7.3130 - pool1_GAP_substract_loss: 10148.0942 - pool2_GAP_substract_loss: 5476.3895 - pool3_GAP_substract_loss: 1841.1101 - conv4_3_norm_GAP_substract_loss: 8.0967 - fc7_GAP_substract_loss: 6.4283 - conv6_2_GAP_substract_loss: 4.4444 - conv7_2_GAP_substract_loss: 3.5778 - conv8_2_GAP_substract_loss: 8.7208 - conv9_2_GAP_substract_loss: 23.1282 - predictions_loss: 4.6485 - val_loss: 9.3241 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.7005\n",
      "\n",
      "Epoch 00010: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-10_loss-7.3130_val_loss-9.3241.h5\n",
      "Epoch 11/120\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1084s 1s/step - loss: 7.1863 - pool1_GAP_substract_loss: 9358.3922 - pool2_GAP_substract_loss: 5100.4190 - pool3_GAP_substract_loss: 1656.9849 - conv4_3_norm_GAP_substract_loss: 8.4987 - fc7_GAP_substract_loss: 6.6468 - conv6_2_GAP_substract_loss: 4.4460 - conv7_2_GAP_substract_loss: 3.7328 - conv8_2_GAP_substract_loss: 9.2796 - conv9_2_GAP_substract_loss: 24.3199 - predictions_loss: 4.5696 - val_loss: 9.1222 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.5443\n",
      "\n",
      "Epoch 00011: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-11_loss-7.1863_val_loss-9.1222.h5\n",
      "Epoch 12/120\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1112s 1s/step - loss: 7.0916 - pool1_GAP_substract_loss: 8726.3028 - pool2_GAP_substract_loss: 4760.6835 - pool3_GAP_substract_loss: 1468.6193 - conv4_3_norm_GAP_substract_loss: 8.6826 - fc7_GAP_substract_loss: 6.7102 - conv6_2_GAP_substract_loss: 4.5036 - conv7_2_GAP_substract_loss: 3.8519 - conv8_2_GAP_substract_loss: 9.5866 - conv9_2_GAP_substract_loss: 24.8891 - predictions_loss: 4.5212 - val_loss: 9.2435 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.7103\n",
      "\n",
      "Epoch 00012: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-12_loss-7.0916_val_loss-9.2435.h5\n",
      "Epoch 13/120\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1080s 1s/step - loss: 7.0118 - pool1_GAP_substract_loss: 8313.8690 - pool2_GAP_substract_loss: 4433.2854 - pool3_GAP_substract_loss: 1365.6748 - conv4_3_norm_GAP_substract_loss: 8.9052 - fc7_GAP_substract_loss: 6.5308 - conv6_2_GAP_substract_loss: 4.3409 - conv7_2_GAP_substract_loss: 3.8213 - conv8_2_GAP_substract_loss: 9.5024 - conv9_2_GAP_substract_loss: 24.6742 - predictions_loss: 4.4864 - val_loss: 9.3007 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.8112\n",
      "\n",
      "Epoch 00013: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-13_loss-7.0118_val_loss-9.3007.h5\n",
      "Epoch 14/120\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1065s 1s/step - loss: 6.9253 - pool1_GAP_substract_loss: 7820.4638 - pool2_GAP_substract_loss: 4239.2465 - pool3_GAP_substract_loss: 1244.9249 - conv4_3_norm_GAP_substract_loss: 9.2901 - fc7_GAP_substract_loss: 6.6770 - conv6_2_GAP_substract_loss: 4.3997 - conv7_2_GAP_substract_loss: 3.9677 - conv8_2_GAP_substract_loss: 9.7067 - conv9_2_GAP_substract_loss: 24.5034 - predictions_loss: 4.4439 - val_loss: 9.4110 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.9641\n",
      "\n",
      "Epoch 00014: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-14_loss-6.9253_val_loss-9.4110.h5\n",
      "Epoch 15/120\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1100s 1s/step - loss: 6.8500 - pool1_GAP_substract_loss: 7312.7999 - pool2_GAP_substract_loss: 4107.1659 - pool3_GAP_substract_loss: 1163.5423 - conv4_3_norm_GAP_substract_loss: 9.4808 - fc7_GAP_substract_loss: 6.6052 - conv6_2_GAP_substract_loss: 4.4458 - conv7_2_GAP_substract_loss: 4.1893 - conv8_2_GAP_substract_loss: 10.6300 - conv9_2_GAP_substract_loss: 26.0592 - predictions_loss: 4.4115 - val_loss: 9.0809 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.6757\n",
      "\n",
      "Epoch 00015: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-15_loss-6.8500_val_loss-9.0809.h5\n",
      "Epoch 16/120\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1120s 1s/step - loss: 6.7664 - pool1_GAP_substract_loss: 7186.4139 - pool2_GAP_substract_loss: 3813.7264 - pool3_GAP_substract_loss: 1085.2360 - conv4_3_norm_GAP_substract_loss: 9.3676 - fc7_GAP_substract_loss: 6.6629 - conv6_2_GAP_substract_loss: 4.3139 - conv7_2_GAP_substract_loss: 4.1534 - conv8_2_GAP_substract_loss: 10.7992 - conv9_2_GAP_substract_loss: 26.5243 - predictions_loss: 4.3694 - val_loss: 9.0030 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.6384\n",
      "\n",
      "Epoch 00016: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-16_loss-6.7664_val_loss-9.0030.h5\n",
      "Epoch 17/120\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1081s 1s/step - loss: 6.6754 - pool1_GAP_substract_loss: 6972.1116 - pool2_GAP_substract_loss: 3769.8155 - pool3_GAP_substract_loss: 1034.5057 - conv4_3_norm_GAP_substract_loss: 9.6231 - fc7_GAP_substract_loss: 6.5138 - conv6_2_GAP_substract_loss: 4.2900 - conv7_2_GAP_substract_loss: 4.1218 - conv8_2_GAP_substract_loss: 10.4641 - conv9_2_GAP_substract_loss: 25.4047 - predictions_loss: 4.3189 - val_loss: 8.9507 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.6257\n",
      "\n",
      "Epoch 00017: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-17_loss-6.6754_val_loss-8.9507.h5\n",
      "Epoch 18/120\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1082s 1s/step - loss: 6.6021 - pool1_GAP_substract_loss: 6471.0825 - pool2_GAP_substract_loss: 3540.4918 - pool3_GAP_substract_loss: 939.0516 - conv4_3_norm_GAP_substract_loss: 9.6039 - fc7_GAP_substract_loss: 6.5780 - conv6_2_GAP_substract_loss: 4.5123 - conv7_2_GAP_substract_loss: 4.3378 - conv8_2_GAP_substract_loss: 11.0284 - conv9_2_GAP_substract_loss: 26.1397 - predictions_loss: 4.2855 - val_loss: 9.0519 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.7656\n",
      "\n",
      "Epoch 00018: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-18_loss-6.6021_val_loss-9.0519.h5\n",
      "Epoch 19/120\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1085s 1s/step - loss: 6.5702 - pool1_GAP_substract_loss: 6326.2745 - pool2_GAP_substract_loss: 3398.3645 - pool3_GAP_substract_loss: 868.9401 - conv4_3_norm_GAP_substract_loss: 9.7621 - fc7_GAP_substract_loss: 6.7262 - conv6_2_GAP_substract_loss: 4.5648 - conv7_2_GAP_substract_loss: 4.5111 - conv8_2_GAP_substract_loss: 11.4269 - conv9_2_GAP_substract_loss: 26.3147 - predictions_loss: 4.2922 - val_loss: 9.1087 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.8601\n",
      "\n",
      "Epoch 00019: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-19_loss-6.5702_val_loss-9.1087.h5\n",
      "Epoch 20/120\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1109s 1s/step - loss: 6.5030 - pool1_GAP_substract_loss: 6171.0690 - pool2_GAP_substract_loss: 3342.2791 - pool3_GAP_substract_loss: 841.2781 - conv4_3_norm_GAP_substract_loss: 10.2613 - fc7_GAP_substract_loss: 6.8040 - conv6_2_GAP_substract_loss: 4.6305 - conv7_2_GAP_substract_loss: 4.6823 - conv8_2_GAP_substract_loss: 11.5495 - conv9_2_GAP_substract_loss: 25.6467 - predictions_loss: 4.2626 - val_loss: 9.0430 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.8314\n",
      "\n",
      "Epoch 00020: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-20_loss-6.5030_val_loss-9.0430.h5\n",
      "Epoch 21/120\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1096s 1s/step - loss: 6.3971 - pool1_GAP_substract_loss: 5831.3090 - pool2_GAP_substract_loss: 3235.2234 - pool3_GAP_substract_loss: 772.2441 - conv4_3_norm_GAP_substract_loss: 10.2160 - fc7_GAP_substract_loss: 6.5136 - conv6_2_GAP_substract_loss: 4.5674 - conv7_2_GAP_substract_loss: 4.7324 - conv8_2_GAP_substract_loss: 12.0746 - conv9_2_GAP_substract_loss: 27.2585 - predictions_loss: 4.1938 - val_loss: 8.7205 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.5449\n",
      "\n",
      "Epoch 00021: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-21_loss-6.3971_val_loss-8.7205.h5\n",
      "Epoch 22/120\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1056s 1s/step - loss: 6.3680 - pool1_GAP_substract_loss: 5664.8891 - pool2_GAP_substract_loss: 3123.3191 - pool3_GAP_substract_loss: 705.8159 - conv4_3_norm_GAP_substract_loss: 10.2645 - fc7_GAP_substract_loss: 6.2933 - conv6_2_GAP_substract_loss: 4.3568 - conv7_2_GAP_substract_loss: 4.5658 - conv8_2_GAP_substract_loss: 11.8030 - conv9_2_GAP_substract_loss: 26.4689 - predictions_loss: 4.2006 - val_loss: 8.8336 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.6933\n",
      "\n",
      "Epoch 00022: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-22_loss-6.3680_val_loss-8.8336.h5\n",
      "Epoch 23/120\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1119s 1s/step - loss: 6.2687 - pool1_GAP_substract_loss: 5662.2310 - pool2_GAP_substract_loss: 3072.5546 - pool3_GAP_substract_loss: 676.6388 - conv4_3_norm_GAP_substract_loss: 10.5370 - fc7_GAP_substract_loss: 6.6129 - conv6_2_GAP_substract_loss: 4.5246 - conv7_2_GAP_substract_loss: 4.6162 - conv8_2_GAP_substract_loss: 11.7462 - conv9_2_GAP_substract_loss: 25.8360 - predictions_loss: 4.1363 - val_loss: 8.6985 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.5927\n",
      "\n",
      "Epoch 00023: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-23_loss-6.2687_val_loss-8.6985.h5\n",
      "Epoch 24/120\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1192s 1s/step - loss: 6.2692 - pool1_GAP_substract_loss: 5328.6046 - pool2_GAP_substract_loss: 2880.6395 - pool3_GAP_substract_loss: 619.8687 - conv4_3_norm_GAP_substract_loss: 10.2400 - fc7_GAP_substract_loss: 6.1341 - conv6_2_GAP_substract_loss: 4.3141 - conv7_2_GAP_substract_loss: 4.4973 - conv8_2_GAP_substract_loss: 11.4103 - conv9_2_GAP_substract_loss: 24.6672 - predictions_loss: 4.1715 - val_loss: 8.8376 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.7654\n",
      "\n",
      "Epoch 00024: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-24_loss-6.2692_val_loss-8.8376.h5\n",
      "Epoch 25/120\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1214s 1s/step - loss: 6.1495 - pool1_GAP_substract_loss: 5315.8604 - pool2_GAP_substract_loss: 2893.4225 - pool3_GAP_substract_loss: 636.9592 - conv4_3_norm_GAP_substract_loss: 10.8989 - fc7_GAP_substract_loss: 6.3789 - conv6_2_GAP_substract_loss: 4.5408 - conv7_2_GAP_substract_loss: 4.8080 - conv8_2_GAP_substract_loss: 12.3275 - conv9_2_GAP_substract_loss: 26.2712 - predictions_loss: 4.0849 - val_loss: 8.9859 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.9466\n",
      "\n",
      "Epoch 00025: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-25_loss-6.1495_val_loss-8.9859.h5\n",
      "Epoch 26/120\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1078s 1s/step - loss: 6.1410 - pool1_GAP_substract_loss: 5153.8852 - pool2_GAP_substract_loss: 2832.6137 - pool3_GAP_substract_loss: 593.5872 - conv4_3_norm_GAP_substract_loss: 10.8698 - fc7_GAP_substract_loss: 6.1789 - conv6_2_GAP_substract_loss: 4.4730 - conv7_2_GAP_substract_loss: 4.7568 - conv8_2_GAP_substract_loss: 12.3747 - conv9_2_GAP_substract_loss: 26.3190 - predictions_loss: 4.1091 - val_loss: 9.2272 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.2200\n",
      "\n",
      "Epoch 00026: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-26_loss-6.1410_val_loss-9.2272.h5\n",
      "Epoch 27/120\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1049s 1s/step - loss: 6.0705 - pool1_GAP_substract_loss: 4959.4677 - pool2_GAP_substract_loss: 2674.6050 - pool3_GAP_substract_loss: 553.2468 - conv4_3_norm_GAP_substract_loss: 11.0168 - fc7_GAP_substract_loss: 6.3076 - conv6_2_GAP_substract_loss: 4.4559 - conv7_2_GAP_substract_loss: 4.8248 - conv8_2_GAP_substract_loss: 12.3804 - conv9_2_GAP_substract_loss: 25.7399 - predictions_loss: 4.0708 - val_loss: 9.0182 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.0424\n",
      "\n",
      "Epoch 00027: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-27_loss-6.0705_val_loss-9.0182.h5\n",
      "Epoch 28/120\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1092s 1s/step - loss: 6.0312 - pool1_GAP_substract_loss: 4883.7190 - pool2_GAP_substract_loss: 2644.4146 - pool3_GAP_substract_loss: 525.7895 - conv4_3_norm_GAP_substract_loss: 11.2663 - fc7_GAP_substract_loss: 6.2041 - conv6_2_GAP_substract_loss: 4.3463 - conv7_2_GAP_substract_loss: 4.7438 - conv8_2_GAP_substract_loss: 12.0002 - conv9_2_GAP_substract_loss: 24.4879 - predictions_loss: 4.0627 - val_loss: 8.8094 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.8642\n",
      "\n",
      "Epoch 00028: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-28_loss-6.0312_val_loss-8.8094.h5\n",
      "Epoch 29/120\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2012s 2s/step - loss: 5.9642 - pool1_GAP_substract_loss: 4909.8649 - pool2_GAP_substract_loss: 2623.0227 - pool3_GAP_substract_loss: 506.4571 - conv4_3_norm_GAP_substract_loss: 11.0887 - fc7_GAP_substract_loss: 6.0005 - conv6_2_GAP_substract_loss: 4.3708 - conv7_2_GAP_substract_loss: 4.9800 - conv8_2_GAP_substract_loss: 13.0167 - conv9_2_GAP_substract_loss: 26.0798 - predictions_loss: 4.0260 - val_loss: 8.7021 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.7869\n",
      "\n",
      "Epoch 00029: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-29_loss-5.9642_val_loss-8.7021.h5\n",
      "Epoch 30/120\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1399s 1s/step - loss: 5.9227 - pool1_GAP_substract_loss: 4660.3470 - pool2_GAP_substract_loss: 2534.0306 - pool3_GAP_substract_loss: 484.1339 - conv4_3_norm_GAP_substract_loss: 11.1339 - fc7_GAP_substract_loss: 6.1083 - conv6_2_GAP_substract_loss: 4.4599 - conv7_2_GAP_substract_loss: 5.0685 - conv8_2_GAP_substract_loss: 12.8568 - conv9_2_GAP_substract_loss: 25.5771 - predictions_loss: 4.0144 - val_loss: 8.8793 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.9932\n",
      "\n",
      "Epoch 00030: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-30_loss-5.9227_val_loss-8.8793.h5\n",
      "Epoch 31/120\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1162s 1s/step - loss: 5.8749 - pool1_GAP_substract_loss: 4732.0930 - pool2_GAP_substract_loss: 2453.9327 - pool3_GAP_substract_loss: 470.1753 - conv4_3_norm_GAP_substract_loss: 11.3942 - fc7_GAP_substract_loss: 6.1642 - conv6_2_GAP_substract_loss: 4.6152 - conv7_2_GAP_substract_loss: 5.2687 - conv8_2_GAP_substract_loss: 13.2192 - conv9_2_GAP_substract_loss: 26.0304 - predictions_loss: 3.9955 - val_loss: 9.1607 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.3032\n",
      "\n",
      "Epoch 00031: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-31_loss-5.8749_val_loss-9.1607.h5\n",
      "Epoch 32/120\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1264s 1s/step - loss: 5.8008 - pool1_GAP_substract_loss: 4521.4204 - pool2_GAP_substract_loss: 2354.6976 - pool3_GAP_substract_loss: 442.9604 - conv4_3_norm_GAP_substract_loss: 11.2625 - fc7_GAP_substract_loss: 5.8679 - conv6_2_GAP_substract_loss: 4.3681 - conv7_2_GAP_substract_loss: 4.9456 - conv8_2_GAP_substract_loss: 12.4700 - conv9_2_GAP_substract_loss: 24.5266 - predictions_loss: 3.9499 - val_loss: 8.7108 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.8811\n",
      "\n",
      "Epoch 00032: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-32_loss-5.8008_val_loss-8.7108.h5\n",
      "Epoch 33/120\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1092s 1s/step - loss: 5.7931 - pool1_GAP_substract_loss: 4545.8161 - pool2_GAP_substract_loss: 2371.4846 - pool3_GAP_substract_loss: 424.2765 - conv4_3_norm_GAP_substract_loss: 11.6420 - fc7_GAP_substract_loss: 5.9893 - conv6_2_GAP_substract_loss: 4.5331 - conv7_2_GAP_substract_loss: 5.2398 - conv8_2_GAP_substract_loss: 13.0668 - conv9_2_GAP_substract_loss: 25.0528 - predictions_loss: 3.9698 - val_loss: 8.5161 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.7136\n",
      "\n",
      "Epoch 00033: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-33_loss-5.7931_val_loss-8.5161.h5\n",
      "Epoch 34/120\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1097s 1s/step - loss: 5.7089 - pool1_GAP_substract_loss: 4471.7099 - pool2_GAP_substract_loss: 2362.4050 - pool3_GAP_substract_loss: 404.8358 - conv4_3_norm_GAP_substract_loss: 11.9653 - fc7_GAP_substract_loss: 6.0059 - conv6_2_GAP_substract_loss: 4.5732 - conv7_2_GAP_substract_loss: 5.2390 - conv8_2_GAP_substract_loss: 13.1182 - conv9_2_GAP_substract_loss: 24.9172 - predictions_loss: 3.9125 - val_loss: 8.7217 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.9457\n",
      "\n",
      "Epoch 00034: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-34_loss-5.7089_val_loss-8.7217.h5\n",
      "Epoch 35/120\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1145s 1s/step - loss: 5.6627 - pool1_GAP_substract_loss: 4391.4312 - pool2_GAP_substract_loss: 2327.0486 - pool3_GAP_substract_loss: 400.9971 - conv4_3_norm_GAP_substract_loss: 11.9563 - fc7_GAP_substract_loss: 5.9849 - conv6_2_GAP_substract_loss: 4.5398 - conv7_2_GAP_substract_loss: 5.2358 - conv8_2_GAP_substract_loss: 13.1455 - conv9_2_GAP_substract_loss: 24.3688 - predictions_loss: 3.8927 - val_loss: 8.9753 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.2253\n",
      "\n",
      "Epoch 00035: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-35_loss-5.6627_val_loss-8.9753.h5\n",
      "Epoch 36/120\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1060s 1s/step - loss: 5.6269 - pool1_GAP_substract_loss: 4311.3464 - pool2_GAP_substract_loss: 2279.3252 - pool3_GAP_substract_loss: 377.7470 - conv4_3_norm_GAP_substract_loss: 11.9278 - fc7_GAP_substract_loss: 5.8497 - conv6_2_GAP_substract_loss: 4.4134 - conv7_2_GAP_substract_loss: 5.1167 - conv8_2_GAP_substract_loss: 13.0708 - conv9_2_GAP_substract_loss: 24.2980 - predictions_loss: 3.8827 - val_loss: 8.9136 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.1890\n",
      "\n",
      "Epoch 00036: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-36_loss-5.6269_val_loss-8.9136.h5\n",
      "Epoch 37/120\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1058s 1s/step - loss: 5.6085 - pool1_GAP_substract_loss: 4238.2723 - pool2_GAP_substract_loss: 2214.7003 - pool3_GAP_substract_loss: 368.5111 - conv4_3_norm_GAP_substract_loss: 11.6871 - fc7_GAP_substract_loss: 5.8349 - conv6_2_GAP_substract_loss: 4.4561 - conv7_2_GAP_substract_loss: 5.3231 - conv8_2_GAP_substract_loss: 13.7675 - conv9_2_GAP_substract_loss: 25.0786 - predictions_loss: 3.8895 - val_loss: 8.9085 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.2086\n",
      "\n",
      "Epoch 00037: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-37_loss-5.6085_val_loss-8.9085.h5\n",
      "Epoch 38/120\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1118s 1s/step - loss: 5.5576 - pool1_GAP_substract_loss: 4241.7388 - pool2_GAP_substract_loss: 2252.2223 - pool3_GAP_substract_loss: 360.4078 - conv4_3_norm_GAP_substract_loss: 12.0694 - fc7_GAP_substract_loss: 5.9054 - conv6_2_GAP_substract_loss: 4.5360 - conv7_2_GAP_substract_loss: 5.3884 - conv8_2_GAP_substract_loss: 13.5295 - conv9_2_GAP_substract_loss: 24.1946 - predictions_loss: 3.8629 - val_loss: 8.8787 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.2029\n",
      "\n",
      "Epoch 00038: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-38_loss-5.5576_val_loss-8.8787.h5\n",
      "Epoch 39/120\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1093s 1s/step - loss: 5.5474 - pool1_GAP_substract_loss: 4193.7704 - pool2_GAP_substract_loss: 2190.6165 - pool3_GAP_substract_loss: 355.0506 - conv4_3_norm_GAP_substract_loss: 12.0710 - fc7_GAP_substract_loss: 5.5829 - conv6_2_GAP_substract_loss: 4.3898 - conv7_2_GAP_substract_loss: 5.3511 - conv8_2_GAP_substract_loss: 13.8289 - conv9_2_GAP_substract_loss: 24.7953 - predictions_loss: 3.8766 - val_loss: 8.6202 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 6.9678\n",
      "\n",
      "Epoch 00039: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-39_loss-5.5474_val_loss-8.6202.h5\n",
      "Epoch 40/120\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1075s 1s/step - loss: 5.4933 - pool1_GAP_substract_loss: 4215.7579 - pool2_GAP_substract_loss: 2160.2239 - pool3_GAP_substract_loss: 342.5941 - conv4_3_norm_GAP_substract_loss: 12.2208 - fc7_GAP_substract_loss: 5.9859 - conv6_2_GAP_substract_loss: 4.5463 - conv7_2_GAP_substract_loss: 5.4564 - conv8_2_GAP_substract_loss: 13.7962 - conv9_2_GAP_substract_loss: 24.5168 - predictions_loss: 3.8458 - val_loss: 8.6389 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.0096\n",
      "\n",
      "Epoch 00040: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-40_loss-5.4933_val_loss-8.6389.h5\n",
      "Epoch 41/120\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1072s 1s/step - loss: 5.4346 - pool1_GAP_substract_loss: 4228.0959 - pool2_GAP_substract_loss: 2143.2945 - pool3_GAP_substract_loss: 346.9230 - conv4_3_norm_GAP_substract_loss: 12.2250 - fc7_GAP_substract_loss: 5.8137 - conv6_2_GAP_substract_loss: 4.5376 - conv7_2_GAP_substract_loss: 5.5007 - conv8_2_GAP_substract_loss: 13.9709 - conv9_2_GAP_substract_loss: 25.0591 - predictions_loss: 3.8099 - val_loss: 8.7627 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.1559\n",
      "\n",
      "Epoch 00041: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-41_loss-5.4346_val_loss-8.7627.h5\n",
      "Epoch 42/120\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1070s 1s/step - loss: 5.4096 - pool1_GAP_substract_loss: 4211.4883 - pool2_GAP_substract_loss: 2163.1836 - pool3_GAP_substract_loss: 342.7887 - conv4_3_norm_GAP_substract_loss: 12.2840 - fc7_GAP_substract_loss: 5.9936 - conv6_2_GAP_substract_loss: 4.7376 - conv7_2_GAP_substract_loss: 5.7893 - conv8_2_GAP_substract_loss: 14.3721 - conv9_2_GAP_substract_loss: 24.8609 - predictions_loss: 3.8072 - val_loss: 8.7413 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.1566\n",
      "\n",
      "Epoch 00042: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-42_loss-5.4096_val_loss-8.7413.h5\n",
      "Epoch 43/120\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1057s 1s/step - loss: 5.3672 - pool1_GAP_substract_loss: 3991.4253 - pool2_GAP_substract_loss: 2037.7314 - pool3_GAP_substract_loss: 313.1838 - conv4_3_norm_GAP_substract_loss: 12.2796 - fc7_GAP_substract_loss: 5.7608 - conv6_2_GAP_substract_loss: 4.6471 - conv7_2_GAP_substract_loss: 5.6934 - conv8_2_GAP_substract_loss: 14.0611 - conv9_2_GAP_substract_loss: 23.8975 - predictions_loss: 3.7871 - val_loss: 8.9143 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.3511\n",
      "\n",
      "Epoch 00043: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-43_loss-5.3672_val_loss-8.9143.h5\n",
      "Epoch 44/120\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1077s 1s/step - loss: 5.3396 - pool1_GAP_substract_loss: 4025.0022 - pool2_GAP_substract_loss: 2062.9716 - pool3_GAP_substract_loss: 318.4550 - conv4_3_norm_GAP_substract_loss: 12.3356 - fc7_GAP_substract_loss: 5.8299 - conv6_2_GAP_substract_loss: 4.5017 - conv7_2_GAP_substract_loss: 5.4781 - conv8_2_GAP_substract_loss: 13.8482 - conv9_2_GAP_substract_loss: 24.0643 - predictions_loss: 3.7807 - val_loss: 8.7699 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.2279\n",
      "\n",
      "Epoch 00044: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-44_loss-5.3396_val_loss-8.7699.h5\n",
      "Epoch 45/120\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1073s 1s/step - loss: 5.3106 - pool1_GAP_substract_loss: 4068.3490 - pool2_GAP_substract_loss: 2034.6450 - pool3_GAP_substract_loss: 311.4267 - conv4_3_norm_GAP_substract_loss: 12.5772 - fc7_GAP_substract_loss: 5.8075 - conv6_2_GAP_substract_loss: 4.5131 - conv7_2_GAP_substract_loss: 5.5926 - conv8_2_GAP_substract_loss: 14.1341 - conv9_2_GAP_substract_loss: 24.2067 - predictions_loss: 3.7725 - val_loss: 8.6015 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.0800\n",
      "\n",
      "Epoch 00045: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-45_loss-5.3106_val_loss-8.6015.h5\n",
      "Epoch 46/120\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1072s 1s/step - loss: 5.2949 - pool1_GAP_substract_loss: 3965.7702 - pool2_GAP_substract_loss: 2060.9088 - pool3_GAP_substract_loss: 305.8981 - conv4_3_norm_GAP_substract_loss: 12.5204 - fc7_GAP_substract_loss: 5.8670 - conv6_2_GAP_substract_loss: 4.7514 - conv7_2_GAP_substract_loss: 5.9809 - conv8_2_GAP_substract_loss: 15.0361 - conv9_2_GAP_substract_loss: 25.4524 - predictions_loss: 3.7771 - val_loss: 8.9415 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.4401\n",
      "\n",
      "Epoch 00046: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-46_loss-5.2949_val_loss-8.9415.h5\n",
      "Epoch 47/120\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1073s 1s/step - loss: 5.2352 - pool1_GAP_substract_loss: 4006.2829 - pool2_GAP_substract_loss: 2009.9977 - pool3_GAP_substract_loss: 288.0612 - conv4_3_norm_GAP_substract_loss: 12.4653 - fc7_GAP_substract_loss: 5.9094 - conv6_2_GAP_substract_loss: 4.6530 - conv7_2_GAP_substract_loss: 5.7243 - conv8_2_GAP_substract_loss: 14.1446 - conv9_2_GAP_substract_loss: 22.9761 - predictions_loss: 3.7374 - val_loss: 8.6906 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.2089\n",
      "\n",
      "Epoch 00047: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-47_loss-5.2352_val_loss-8.6906.h5\n",
      "Epoch 48/120\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1159s 1s/step - loss: 5.2140 - pool1_GAP_substract_loss: 3976.2754 - pool2_GAP_substract_loss: 2004.4759 - pool3_GAP_substract_loss: 277.5085 - conv4_3_norm_GAP_substract_loss: 12.4026 - fc7_GAP_substract_loss: 5.9063 - conv6_2_GAP_substract_loss: 4.7636 - conv7_2_GAP_substract_loss: 5.9977 - conv8_2_GAP_substract_loss: 14.7463 - conv9_2_GAP_substract_loss: 23.8346 - predictions_loss: 3.7356 - val_loss: 9.0729 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.6102\n",
      "\n",
      "Epoch 00048: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-48_loss-5.2140_val_loss-9.0729.h5\n",
      "Epoch 49/120\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1134s 1s/step - loss: 5.1931 - pool1_GAP_substract_loss: 3952.8397 - pool2_GAP_substract_loss: 2046.8855 - pool3_GAP_substract_loss: 282.7899 - conv4_3_norm_GAP_substract_loss: 13.3097 - fc7_GAP_substract_loss: 6.0839 - conv6_2_GAP_substract_loss: 5.0072 - conv7_2_GAP_substract_loss: 6.4673 - conv8_2_GAP_substract_loss: 16.3203 - conv9_2_GAP_substract_loss: 27.0589 - predictions_loss: 3.7335 - val_loss: 8.8709 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.4268\n",
      "\n",
      "Epoch 00049: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-49_loss-5.1931_val_loss-8.8709.h5\n",
      "Epoch 50/120\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1199s 1s/step - loss: 5.1465 - pool1_GAP_substract_loss: 3866.3806 - pool2_GAP_substract_loss: 1985.9026 - pool3_GAP_substract_loss: 266.1185 - conv4_3_norm_GAP_substract_loss: 12.5999 - fc7_GAP_substract_loss: 5.7991 - conv6_2_GAP_substract_loss: 4.6156 - conv7_2_GAP_substract_loss: 5.8277 - conv8_2_GAP_substract_loss: 14.3727 - conv9_2_GAP_substract_loss: 23.4458 - predictions_loss: 3.7055 - val_loss: 8.7127 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.2870\n",
      "\n",
      "Epoch 00050: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-50_loss-5.1465_val_loss-8.7127.h5\n",
      "Epoch 51/120\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1322s 1s/step - loss: 5.1278 - pool1_GAP_substract_loss: 3887.3808 - pool2_GAP_substract_loss: 1933.2832 - pool3_GAP_substract_loss: 261.9999 - conv4_3_norm_GAP_substract_loss: 12.7050 - fc7_GAP_substract_loss: 5.7419 - conv6_2_GAP_substract_loss: 4.7500 - conv7_2_GAP_substract_loss: 6.1255 - conv8_2_GAP_substract_loss: 15.3859 - conv9_2_GAP_substract_loss: 24.7441 - predictions_loss: 3.7049 - val_loss: 8.7867 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.3787\n",
      "\n",
      "Epoch 00051: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-51_loss-5.1278_val_loss-8.7867.h5\n",
      "Epoch 52/120\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1449s 1s/step - loss: 5.0900 - pool1_GAP_substract_loss: 3821.7731 - pool2_GAP_substract_loss: 1930.0151 - pool3_GAP_substract_loss: 263.5954 - conv4_3_norm_GAP_substract_loss: 12.8501 - fc7_GAP_substract_loss: 5.7845 - conv6_2_GAP_substract_loss: 4.8063 - conv7_2_GAP_substract_loss: 6.2290 - conv8_2_GAP_substract_loss: 15.2720 - conv9_2_GAP_substract_loss: 24.0534 - predictions_loss: 3.6847 - val_loss: 9.5917 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 8.2012\n",
      "\n",
      "Epoch 00052: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-52_loss-5.0900_val_loss-9.5917.h5\n",
      "Epoch 53/120\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1318s 1s/step - loss: 5.0442 - pool1_GAP_substract_loss: 3804.0774 - pool2_GAP_substract_loss: 1953.8599 - pool3_GAP_substract_loss: 265.8352 - conv4_3_norm_GAP_substract_loss: 12.7815 - fc7_GAP_substract_loss: 5.7066 - conv6_2_GAP_substract_loss: 4.8039 - conv7_2_GAP_substract_loss: 6.3042 - conv8_2_GAP_substract_loss: 15.5470 - conv9_2_GAP_substract_loss: 23.9044 - predictions_loss: 3.6563 - val_loss: 8.5496 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.1762\n",
      "\n",
      "Epoch 00053: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-53_loss-5.0442_val_loss-8.5496.h5\n",
      "Epoch 54/120\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1042s 1s/step - loss: 5.0511 - pool1_GAP_substract_loss: 3817.3309 - pool2_GAP_substract_loss: 1899.8552 - pool3_GAP_substract_loss: 254.0860 - conv4_3_norm_GAP_substract_loss: 13.0065 - fc7_GAP_substract_loss: 5.7737 - conv6_2_GAP_substract_loss: 4.8661 - conv7_2_GAP_substract_loss: 6.4559 - conv8_2_GAP_substract_loss: 16.0594 - conv9_2_GAP_substract_loss: 24.3805 - predictions_loss: 3.6799 - val_loss: 8.9871 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.6300\n",
      "\n",
      "Epoch 00054: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-54_loss-5.0511_val_loss-8.9871.h5\n",
      "Epoch 55/120\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1060s 1s/step - loss: 5.0045 - pool1_GAP_substract_loss: 3782.0410 - pool2_GAP_substract_loss: 1923.8782 - pool3_GAP_substract_loss: 252.7427 - conv4_3_norm_GAP_substract_loss: 13.1472 - fc7_GAP_substract_loss: 5.7549 - conv6_2_GAP_substract_loss: 4.9397 - conv7_2_GAP_substract_loss: 6.5513 - conv8_2_GAP_substract_loss: 15.8427 - conv9_2_GAP_substract_loss: 23.6869 - predictions_loss: 3.6496 - val_loss: 8.7896 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.4488\n",
      "\n",
      "Epoch 00055: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-55_loss-5.0045_val_loss-8.7896.h5\n",
      "Epoch 56/120\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1093s 1s/step - loss: 5.0154 - pool1_GAP_substract_loss: 3728.2597 - pool2_GAP_substract_loss: 1833.4950 - pool3_GAP_substract_loss: 243.8463 - conv4_3_norm_GAP_substract_loss: 13.2424 - fc7_GAP_substract_loss: 5.7628 - conv6_2_GAP_substract_loss: 4.9303 - conv7_2_GAP_substract_loss: 6.5315 - conv8_2_GAP_substract_loss: 15.9183 - conv9_2_GAP_substract_loss: 23.7466 - predictions_loss: 3.6767 - val_loss: 8.7452 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.4203\n",
      "\n",
      "Epoch 00056: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-56_loss-5.0154_val_loss-8.7452.h5\n",
      "Epoch 57/120\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1090s 1s/step - loss: 4.9630 - pool1_GAP_substract_loss: 3776.8687 - pool2_GAP_substract_loss: 1827.9209 - pool3_GAP_substract_loss: 233.5767 - conv4_3_norm_GAP_substract_loss: 12.2232 - fc7_GAP_substract_loss: 5.6693 - conv6_2_GAP_substract_loss: 4.9642 - conv7_2_GAP_substract_loss: 6.6713 - conv8_2_GAP_substract_loss: 15.8237 - conv9_2_GAP_substract_loss: 22.8818 - predictions_loss: 3.6399 - val_loss: 8.7388 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.4294\n",
      "\n",
      "Epoch 00057: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-57_loss-4.9630_val_loss-8.7388.h5\n",
      "Epoch 58/120\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1045s 1s/step - loss: 4.9259 - pool1_GAP_substract_loss: 3757.0344 - pool2_GAP_substract_loss: 1827.2520 - pool3_GAP_substract_loss: 235.0619 - conv4_3_norm_GAP_substract_loss: 12.7357 - fc7_GAP_substract_loss: 5.8041 - conv6_2_GAP_substract_loss: 4.9308 - conv7_2_GAP_substract_loss: 6.4924 - conv8_2_GAP_substract_loss: 15.6653 - conv9_2_GAP_substract_loss: 22.9376 - predictions_loss: 3.6182 - val_loss: 9.0786 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.7844\n",
      "\n",
      "Epoch 00058: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-58_loss-4.9259_val_loss-9.0786.h5\n",
      "Epoch 59/120\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1064s 1s/step - loss: 4.9040 - pool1_GAP_substract_loss: 3785.5648 - pool2_GAP_substract_loss: 1831.0321 - pool3_GAP_substract_loss: 226.8611 - conv4_3_norm_GAP_substract_loss: 13.0016 - fc7_GAP_substract_loss: 5.8783 - conv6_2_GAP_substract_loss: 4.9735 - conv7_2_GAP_substract_loss: 6.5580 - conv8_2_GAP_substract_loss: 16.2157 - conv9_2_GAP_substract_loss: 24.0669 - predictions_loss: 3.6113 - val_loss: 8.8057 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.5261\n",
      "\n",
      "Epoch 00059: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-59_loss-4.9040_val_loss-8.8057.h5\n",
      "Epoch 60/120\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 1069s 1s/step - loss: 4.8889 - pool1_GAP_substract_loss: 3671.0114 - pool2_GAP_substract_loss: 1777.5595 - pool3_GAP_substract_loss: 223.3507 - conv4_3_norm_GAP_substract_loss: 12.9248 - fc7_GAP_substract_loss: 5.9293 - conv6_2_GAP_substract_loss: 5.0598 - conv7_2_GAP_substract_loss: 6.6425 - conv8_2_GAP_substract_loss: 16.0151 - conv9_2_GAP_substract_loss: 23.1139 - predictions_loss: 3.6110 - val_loss: 8.8862 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.6212\n",
      "\n",
      "Epoch 00060: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-60_loss-4.8889_val_loss-8.8862.h5\n",
      "Epoch 61/120\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 1078s 1s/step - loss: 4.7012 - pool1_GAP_substract_loss: 3695.3683 - pool2_GAP_substract_loss: 1728.4556 - pool3_GAP_substract_loss: 226.9736 - conv4_3_norm_GAP_substract_loss: 12.5567 - fc7_GAP_substract_loss: 6.0261 - conv6_2_GAP_substract_loss: 5.3136 - conv7_2_GAP_substract_loss: 7.1513 - conv8_2_GAP_substract_loss: 17.4648 - conv9_2_GAP_substract_loss: 24.7542 - predictions_loss: 3.4316 - val_loss: 8.7765 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.5135\n",
      "\n",
      "Epoch 00061: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-61_loss-4.7012_val_loss-8.7765.h5\n",
      "Epoch 62/120\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 1094s 1s/step - loss: 4.6554 - pool1_GAP_substract_loss: 3515.5535 - pool2_GAP_substract_loss: 1738.5651 - pool3_GAP_substract_loss: 234.4338 - conv4_3_norm_GAP_substract_loss: 12.5330 - fc7_GAP_substract_loss: 6.1022 - conv6_2_GAP_substract_loss: 5.4551 - conv7_2_GAP_substract_loss: 7.2782 - conv8_2_GAP_substract_loss: 17.2561 - conv9_2_GAP_substract_loss: 24.0003 - predictions_loss: 3.3880 - val_loss: 8.8186 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.5577\n",
      "\n",
      "Epoch 00062: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-62_loss-4.6554_val_loss-8.8186.h5\n",
      "Epoch 63/120\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 1068s 1s/step - loss: 4.6147 - pool1_GAP_substract_loss: 3623.2363 - pool2_GAP_substract_loss: 1814.9847 - pool3_GAP_substract_loss: 245.7494 - conv4_3_norm_GAP_substract_loss: 12.5207 - fc7_GAP_substract_loss: 6.2601 - conv6_2_GAP_substract_loss: 5.6695 - conv7_2_GAP_substract_loss: 7.5990 - conv8_2_GAP_substract_loss: 17.9469 - conv9_2_GAP_substract_loss: 24.8032 - predictions_loss: 3.3490 - val_loss: 8.7972 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.5383\n",
      "\n",
      "Epoch 00063: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-63_loss-4.6147_val_loss-8.7972.h5\n",
      "Epoch 64/120\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 1084s 1s/step - loss: 4.6429 - pool1_GAP_substract_loss: 3578.3310 - pool2_GAP_substract_loss: 1834.9287 - pool3_GAP_substract_loss: 251.8378 - conv4_3_norm_GAP_substract_loss: 12.4993 - fc7_GAP_substract_loss: 6.2662 - conv6_2_GAP_substract_loss: 5.7831 - conv7_2_GAP_substract_loss: 7.8904 - conv8_2_GAP_substract_loss: 18.7345 - conv9_2_GAP_substract_loss: 25.8797 - predictions_loss: 3.3793 - val_loss: 8.8100 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.5530\n",
      "\n",
      "Epoch 00064: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-64_loss-4.6429_val_loss-8.8100.h5\n",
      "Epoch 65/120\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 1056s 1s/step - loss: 4.6086 - pool1_GAP_substract_loss: 3549.0438 - pool2_GAP_substract_loss: 1847.5125 - pool3_GAP_substract_loss: 257.9272 - conv4_3_norm_GAP_substract_loss: 12.5860 - fc7_GAP_substract_loss: 6.4558 - conv6_2_GAP_substract_loss: 5.9648 - conv7_2_GAP_substract_loss: 8.0764 - conv8_2_GAP_substract_loss: 18.8320 - conv9_2_GAP_substract_loss: 25.6754 - predictions_loss: 3.3470 - val_loss: 8.7818 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.5268\n",
      "\n",
      "Epoch 00065: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-65_loss-4.6086_val_loss-8.7818.h5\n",
      "Epoch 66/120\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 1092s 1s/step - loss: 4.5782 - pool1_GAP_substract_loss: 3580.5566 - pool2_GAP_substract_loss: 1858.1864 - pool3_GAP_substract_loss: 262.1903 - conv4_3_norm_GAP_substract_loss: 12.6960 - fc7_GAP_substract_loss: 6.4432 - conv6_2_GAP_substract_loss: 6.0883 - conv7_2_GAP_substract_loss: 8.2921 - conv8_2_GAP_substract_loss: 19.3220 - conv9_2_GAP_substract_loss: 26.3060 - predictions_loss: 3.3185 - val_loss: 8.9891 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.7361\n",
      "\n",
      "Epoch 00066: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-66_loss-4.5782_val_loss-8.9891.h5\n",
      "Epoch 67/120\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 1122s 1s/step - loss: 4.5811 - pool1_GAP_substract_loss: 3582.7271 - pool2_GAP_substract_loss: 1861.7323 - pool3_GAP_substract_loss: 263.7952 - conv4_3_norm_GAP_substract_loss: 12.7126 - fc7_GAP_substract_loss: 6.3713 - conv6_2_GAP_substract_loss: 6.0623 - conv7_2_GAP_substract_loss: 8.2182 - conv8_2_GAP_substract_loss: 19.1223 - conv9_2_GAP_substract_loss: 25.8826 - predictions_loss: 3.3234 - val_loss: 8.8476 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.5966\n",
      "\n",
      "Epoch 00067: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-67_loss-4.5811_val_loss-8.8476.h5\n",
      "Epoch 68/120\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 1198s 1s/step - loss: 4.5686 - pool1_GAP_substract_loss: 3581.9419 - pool2_GAP_substract_loss: 1891.8752 - pool3_GAP_substract_loss: 274.3817 - conv4_3_norm_GAP_substract_loss: 12.7423 - fc7_GAP_substract_loss: 6.5798 - conv6_2_GAP_substract_loss: 6.2977 - conv7_2_GAP_substract_loss: 8.5275 - conv8_2_GAP_substract_loss: 19.8854 - conv9_2_GAP_substract_loss: 27.1632 - predictions_loss: 3.3128 - val_loss: 8.8459 - val_pool1_GAP_substract_loss: 0.0000e+00 - val_pool2_GAP_substract_loss: 0.0000e+00 - val_pool3_GAP_substract_loss: 0.0000e+00 - val_conv4_3_norm_GAP_substract_loss: 0.0000e+00 - val_fc7_GAP_substract_loss: 0.0000e+00 - val_conv6_2_GAP_substract_loss: 0.0000e+00 - val_conv7_2_GAP_substract_loss: 0.0000e+00 - val_conv8_2_GAP_substract_loss: 0.0000e+00 - val_conv9_2_GAP_substract_loss: 0.0000e+00 - val_predictions_loss: 7.5968\n",
      "\n",
      "Epoch 00068: saving model to ../trained_weights/City_to_foggy0_02_resize_600_1200/current/pool123_loss_weights_0_000001/epoch-68_loss-4.5686_val_loss-8.8459.h5\n",
      "Epoch 69/120\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.0001.\n",
      "  16/1000 [..............................] - ETA: 11:00 - loss: 4.4894 - pool1_GAP_substract_loss: 3102.0499 - pool2_GAP_substract_loss: 1676.3834 - pool3_GAP_substract_loss: 252.5215 - conv4_3_norm_GAP_substract_loss: 12.1167 - fc7_GAP_substract_loss: 6.2848 - conv6_2_GAP_substract_loss: 6.1863 - conv7_2_GAP_substract_loss: 7.9754 - conv8_2_GAP_substract_loss: 17.5166 - conv9_2_GAP_substract_loss: 22.6594 - predictions_loss: 3.2353"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ea67b764e796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_epoch = 0\n",
    "final_epoch = 120\n",
    "steps_per_epoch = 1000\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Set the generator for the val_dataset or train_dataset predictions.\n",
    "\n",
    "predict_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=None,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'filenames',\n",
    "                                                  'inverse_transform',\n",
    "                                                  'original_images',\n",
    "                                                  'original_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "# 2: Generate samples.\n",
    "\n",
    "batch_images, batch_filenames, batch_inverse_transforms, batch_original_images, batch_original_labels = next(predict_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_images, batch_filenames, batch_inverse_transforms, batch_original_images, batch_original_labels = next(predict_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 5\n",
    "print(\"Image:\", batch_filenames[i])\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, n_classes+1)).tolist()\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.imshow(batch_images[0][i])\n",
    "plt.show()\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.imshow(batch_images[1][i])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  # Which batch item to look at\n",
    "\n",
    "print(\"Image:\", batch_filenames[i])\n",
    "print()\n",
    "print(\"Ground truth boxes:\\n\")\n",
    "print(np.array(batch_original_labels[i]))\n",
    "\n",
    "# 3: Make predictions.\n",
    "\n",
    "y_pred = model.predict(batch_images)[-1]\n",
    "\n",
    "# Now let's decode the raw predictions in `y_pred`.\n",
    "\n",
    "# Had we created the model in 'inference' or 'inference_fast' mode,\n",
    "# then the model's final layer would be a `DecodeDetections` layer and\n",
    "# `y_pred` would already contain the decoded predictions,\n",
    "# but since we created the model in 'training' mode,\n",
    "# the model outputs raw predictions that still need to be decoded and filtered.\n",
    "# This is what the `decode_detections()` function is for.\n",
    "# It does exactly what the `DecodeDetections` layer would do,\n",
    "# but using Numpy instead of TensorFlow (i.e. on the CPU instead of the GPU).\n",
    "\n",
    "# `decode_detections()` with default argument values follows the procedure of the original SSD implementation:\n",
    "# First, a very low confidence threshold of 0.01 is applied to filter out the majority of the predicted boxes,\n",
    "# then greedy non-maximum suppression is performed per class with an intersection-over-union threshold of 0.45,\n",
    "# and out of what is left after that, the top 200 highest confidence boxes are returned.\n",
    "# Those settings are for precision-recall scoring purposes though.\n",
    "# In order to get some usable final predictions, we'll set the confidence threshold much higher, e.g. to 0.5,\n",
    "# since we're only interested in the very confident predictions.\n",
    "\n",
    "# 4: Decode the raw predictions in `y_pred`.\n",
    "\n",
    "y_pred_decoded = decode_detections(y_pred,\n",
    "                                   confidence_thresh=0.35,\n",
    "                                   iou_threshold=0.4,\n",
    "                                   top_k=200,\n",
    "                                   normalize_coords=normalize_coords,\n",
    "                                   img_height=img_height,\n",
    "                                   img_width=img_width)\n",
    "\n",
    "# We made the predictions on the resized images,\n",
    "# but we'd like to visualize the outcome on the original input images,\n",
    "# so we'll convert the coordinates accordingly.\n",
    "# Don't worry about that opaque `apply_inverse_transforms()` function below,\n",
    "# in this simple case it just applies `(* original_image_size / resized_image_size)` to the box coordinates.\n",
    "\n",
    "# 5: Convert the predictions for the original image.\n",
    "\n",
    "y_pred_decoded_inv = apply_inverse_transforms(y_pred_decoded, batch_inverse_transforms)\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "print(\"Predicted boxes:\\n\")\n",
    "print('   class   conf xmin   ymin   xmax   ymax')\n",
    "print(y_pred_decoded_inv[i])\n",
    "\n",
    "# Finally, let's draw the predicted boxes onto the image.\n",
    "# Each predicted box says its confidence next to the category name.\n",
    "# The ground truth boxes are also drawn onto the image in green for comparison.\n",
    "\n",
    "# 5: Draw the predicted boxes onto the image\n",
    "\n",
    "# Set the colors for the bounding boxes\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, n_classes+1)).tolist()\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.imshow(batch_original_images[i])\n",
    "\n",
    "current_axis = plt.gca()\n",
    "\n",
    "for box in batch_original_labels[i]:\n",
    "    xmin = box[1]\n",
    "    ymin = box[2]\n",
    "    xmax = box[3]\n",
    "    ymax = box[4]\n",
    "    label = '{}'.format(classes[int(box[0])])\n",
    "    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color='green', fill=False, linewidth=2))\n",
    "    current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor': 'green', 'alpha': 1.0})\n",
    "\n",
    "# for box in y_pred_decoded_inv[i]:\n",
    "#     xmin = box[2]\n",
    "#     ymin = box[3]\n",
    "#     xmax = box[4]\n",
    "#     ymax = box[5]\n",
    "#     color = colors[int(box[0])]\n",
    "#     label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
    "#     current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))\n",
    "#     current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor': color, 'alpha': 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
